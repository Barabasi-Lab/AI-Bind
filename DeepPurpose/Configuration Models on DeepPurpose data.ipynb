{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bicm import BipartiteGraph\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('DeepPurpose_train.csv')\n",
    "test = pd.read_csv('DeepPurpose_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Ligand and Target Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"ligands.txt\", \"r\") # Rows of the adjacency matrix in order\n",
    "ligands = text_file.readlines()\n",
    "\n",
    "text_file = open(\"targets.txt\", \"r\") # Columns of the adjacency matrix in order \n",
    "targets = text_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10416/10416 [00:00<00:00, 1077515.61it/s]\n",
      "100%|██████████| 1391/1391 [00:00<00:00, 745118.37it/s]\n"
     ]
    }
   ],
   "source": [
    "ligands = [j.replace('\\n','') for j in tqdm(ligands)]\n",
    "targets = [j.replace('\\n','') for j in tqdm(targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ligands:  10416\n",
      "Targets:  1391\n"
     ]
    }
   ],
   "source": [
    "number_ligands = len(ligands)\n",
    "number_targets = len(targets)\n",
    "print('Ligands: ', number_ligands)\n",
    "print('Targets: ',number_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Degree Ratio Dictionaries from Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = train[train['Label'] == 1]\n",
    "train_neg = train[train['Label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10416/10416 [01:01<00:00, 168.67it/s]\n"
     ]
    }
   ],
   "source": [
    "ligand_degree_ratio = dict()\n",
    "ligand_all_average = []\n",
    "\n",
    "for ligand in tqdm(ligands):\n",
    "    pos_deg = len(train_pos[train_pos['SMILES'] == ligand])\n",
    "    neg_deg = len(train_neg[train_neg['SMILES'] == ligand])\n",
    "    ligand_degree_ratio[ligand] = dict()\n",
    "    ligand_degree_ratio[ligand]['deg_ratio'] = pos_deg / (pos_deg + neg_deg)\n",
    "    ligand_degree_ratio[ligand]['deg_avg'] = pos_deg / number_targets \n",
    "    ligand_all_average.append(pos_deg / number_targets)\n",
    "    \n",
    "ligands_all_avg = sum(ligand_all_average) / number_ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1391/1391 [00:08<00:00, 169.54it/s]\n"
     ]
    }
   ],
   "source": [
    "targets_degree_ratio = dict()\n",
    "target_all_average = []\n",
    "\n",
    "for target in tqdm(targets):\n",
    "    pos_deg = len(train_pos[train_pos['Target Sequence'] == target])\n",
    "    neg_deg = len(train_neg[train_neg['Target Sequence'] == target])\n",
    "    targets_degree_ratio[target] = dict()\n",
    "    targets_degree_ratio[target]['deg_ratio'] = pos_deg / (pos_deg + neg_deg)\n",
    "    targets_degree_ratio[target]['deg_avg'] = pos_deg / number_ligands\n",
    "    target_all_average.append(pos_deg / number_ligands)\n",
    "    \n",
    "targets_all_avg = sum(target_all_average) / number_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14150it [00:04, 3288.28it/s]\n"
     ]
    }
   ],
   "source": [
    "test_probabilty_predicted_naive = []\n",
    "\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    \n",
    "    if row['SMILES'] in ligands and row['Target Sequence'] in targets:\n",
    "        p_naive = ligand_degree_ratio[row['SMILES']]['deg_ratio'] * targets_degree_ratio[row['Target Sequence']]['deg_ratio']\n",
    "        test_probabilty_predicted_naive.append(min(1,p_naive))\n",
    "    elif row['SMILES'] in ligands and row['Target Sequence'] not in targets:\n",
    "        p_naive = ligand_degree_ratio[row['SMILES']]['deg_ratio']  \n",
    "        test_probabilty_predicted_naive.append(min(1,p_naive))\n",
    "    elif row['SMILES'] not in ligands and row['Target Sequence'] in targets:\n",
    "        p_naive = targets_degree_ratio[row['Target Sequence']]['deg_ratio'] \n",
    "        test_probabilty_predicted_naive.append(min(1,p_naive))\n",
    "    else:\n",
    "        test_probabilty_predicted_naive.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8491380951089191\n",
      "AUP:  0.6402460532069669\n"
     ]
    }
   ],
   "source": [
    "## Performance on the test dataset\n",
    "\n",
    "print('AUC: ', roc_auc_score(test['Label'].tolist(), test_probabilty_predicted_naive))\n",
    "print('AUP: ', average_precision_score(test['Label'].tolist(), test_probabilty_predicted_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Model - Single Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.loadtxt(open(\"P.csv\", \"rb\"), delimiter=\",\", skiprows=0) # Output of MATLAB run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14150it [00:13, 1011.22it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_probability_test_single_layer = []\n",
    "\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    if row['SMILES'] in ligands and row['Target Sequence'] in targets:\n",
    "        p = P[ligands.index(row['SMILES']),targets.index(row['Target Sequence'])]\n",
    "    elif row['SMILES'] in ligands and row['Target Sequence'] not in targets:\n",
    "        p = sum(P[ligands.index(row['SMILES']),:]) / len(targets) # Average binding probaility of the ligand\n",
    "    elif row['SMILES'] not in ligands and row['Target Sequence'] in targets:\n",
    "        p = sum(P[:,targets.index(row['Target Sequence'])]) / len(ligands) # Average binding probability of the target\n",
    "    else:\n",
    "        p = np.sum(P) / (len(ligands)*len(targets)) # Both unseen - average over all probabilties \n",
    "                  \n",
    "    predicted_probability_test_single_layer.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6718648547306816\n",
      "AUP:  0.3579757116887733\n"
     ]
    }
   ],
   "source": [
    "## Performance on the test dataset\n",
    "\n",
    "print('AUC: ', roc_auc_score(test['Label'].tolist(), predicted_probability_test_single_layer))\n",
    "print('AUP: ', average_precision_score(test['Label'].tolist(), predicted_probability_test_single_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Model - Duplex - Unconditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "summat10 = np.loadtxt(open(\"summat10.csv\", \"rb\"), delimiter=\",\", skiprows=0) # Output of MATLAB run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "summat01 = np.loadtxt(open(\"summat01.csv\", \"rb\"), delimiter=\",\", skiprows=0) # Output of MATLAB run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14150it [00:13, 1027.07it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_probability_test_unconditioned = []\n",
    "\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    if row['SMILES'] in ligands and row['Target Sequence'] in targets:\n",
    "        p10 = summat10[ligands.index(row['SMILES']),targets.index(row['Target Sequence'])]\n",
    "    elif row['SMILES'] in ligands and row['Target Sequence'] not in targets:\n",
    "        p10 = sum(summat10[ligands.index(row['SMILES']),:]) / len(targets) # Average binding probbaility of the ligand\n",
    "    elif row['SMILES'] not in ligands and row['Target Sequence'] in targets:\n",
    "        p10 = sum(summat10[:,targets.index(row['Target Sequence'])]) / len(ligands) # Average binding probability of the target\n",
    "    else:\n",
    "        p10 = np.sum(summat10) / (len(ligands)*len(targets)) # Both unseen - average over all probabilties \n",
    "                  \n",
    "    predicted_probability_test_unconditioned.append(p10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6718648547306816\n",
      "AUP:  0.3579757116887733\n"
     ]
    }
   ],
   "source": [
    "## Performance on the test dataset\n",
    "\n",
    "print('AUC: ', roc_auc_score(test['Label'].tolist(), predicted_probability_test_unconditioned))\n",
    "print('AUP: ', average_precision_score(test['Label'].tolist(), predicted_probability_test_unconditioned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Model - Duplex - Conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "1479it [00:00, 2092.49it/s]/miniconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "14150it [00:06, 2123.63it/s]\n"
     ]
    }
   ],
   "source": [
    "test_probabilty_predicted_conditioned = []\n",
    "\n",
    "## Average conditional probability\n",
    "conditoned_summat = np.divide(summat10,np.add(summat10,summat01)) # Elementwise pos_deg / (pos_deg + neg_deg)\n",
    "conditoned_summat = np.nan_to_num(conditoned_summat)\n",
    "conditoned_summat = np.minimum(conditoned_summat,1) # Take minimum of 1 and the computed conditional probability \n",
    "average_conditional_probability = np.sum(conditoned_summat) / (number_ligands * number_targets)\n",
    "\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    \n",
    "    if row['SMILES'] in ligands and row['Target Sequence'] in targets:\n",
    "        p10 = summat10[ligands.index(row['SMILES']),targets.index(row['Target Sequence'])]\n",
    "        p01 = summat01[ligands.index(row['SMILES']),targets.index(row['Target Sequence'])]\n",
    "        p10_conditioned = p10 / (p10 + p01)\n",
    "        test_probabilty_predicted_conditioned.append(min(1,p10_conditioned))\n",
    "    elif row['SMILES'] in ligands and row['Target Sequence'] not in targets:\n",
    "        p10_conditioned = ligand_degree_ratio[row['SMILES']]['deg_ratio']  \n",
    "        test_probabilty_predicted_conditioned.append(min(1,p10_conditioned))\n",
    "    elif row['SMILES'] not in ligands and row['Target Sequence'] in targets:\n",
    "        p10_conditioned = targets_degree_ratio[row['Target Sequence']]['deg_ratio'] \n",
    "        test_probabilty_predicted_conditioned.append(min(1,p10_conditioned))\n",
    "    else:\n",
    "        p10_conditioned = average_conditional_probability\n",
    "        test_probabilty_predicted_conditioned.append(p10_conditioned)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8543987955332084\n",
      "AUP:  0.6452633855586876\n"
     ]
    }
   ],
   "source": [
    "## Performance on the test dataset\n",
    "\n",
    "print('AUC: ', roc_auc_score(test['Label'].tolist(), test_probabilty_predicted_conditioned))\n",
    "print('AUP: ', average_precision_score(test['Label'].tolist(), test_probabilty_predicted_conditioned))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
