{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda/lib/python3.6/site-packages/rdkit/Chem/PandasTools.py\", line 130, in <module>\n",
      "    if 'display.width' in pd.core.config._registered_options:\n",
      "AttributeError: module 'pandas.core' has no attribute 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import json\n",
    "import lxml\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import plotly.graph_objects as go\n",
    "import umap.umap_ as umap\n",
    "import tensorflow.keras\n",
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from pandarallel import pandarallel\n",
    "from ast import literal_eval\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import Counter\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "\n",
    "from mol2vec import features\n",
    "from mol2vec import helpers\n",
    "from mol2vec.features import mol2alt_sentence, MolSentence, DfVec, sentences2vec\n",
    "from mol2vec.helpers import depict_identifier, plot_2D_vectors, IdentifierTable, mol_to_svg\n",
    "\n",
    "from Bio import SeqUtils\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Conv1D, Flatten, MaxPooling1D,\\\n",
    "                        AveragePooling1D, Concatenate, LeakyReLU, Embedding,\\\n",
    "                        GlobalMaxPooling1D,GlobalAveragePooling1D,GaussianNoise,BatchNormalization,Add\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "pandarallel.initialize(progress_bar = True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GPU Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'Wed Jun 16 20:56:23 2021       \",\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " '| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |',\n",
       " '|-------------------------------+----------------------+----------------------+',\n",
       " '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |',\n",
       " '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |',\n",
       " '|===============================+======================+======================|',\n",
       " '|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |',\n",
       " '| N/A   65C    P0    30W /  70W |      0MiB / 15079MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |',\n",
       " '| N/A   75C    P0    34W /  70W |      0MiB / 15079MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '|   2  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |',\n",
       " '| N/A   76C    P0    34W /  70W |      0MiB / 15079MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '|   3  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |',\n",
       " '| N/A   69C    P0    32W /  70W |      0MiB / 15079MiB |      5%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '                                                                               ',\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " '| Processes:                                                       GPU Memory |',\n",
       " '|  GPU       PID   Type   Process name                             Usage      |',\n",
       " '|=============================================================================|',\n",
       " '|  No running processes found                                                 |',\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(subprocess.check_output('nvidia-smi', shell = True)).split('\\\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AIBind():\n",
    "\n",
    "    # Class Initialisation\n",
    "    def __init__(self,\n",
    "\n",
    "                 interactions_location = None,\n",
    "                 interactions = None,\n",
    "                 interaction_y_name = 'Y',\n",
    "                 \n",
    "                 absolute_negatives_location = None,\n",
    "                 absolute_negatives = None,\n",
    "\n",
    "                 drugs_location = None,\n",
    "                 drugs_dataframe = None,\n",
    "                 drug_inchi_name = None,\n",
    "                 drug_smile_name = None,\n",
    "\n",
    "                 targets_location = None,\n",
    "                 targets_dataframe = None, \n",
    "                 target_seq_name = None,\n",
    "\n",
    "                 mol2vec_location = None,\n",
    "                 mol2vec_model = None,\n",
    "\n",
    "                 protvec_location = None, \n",
    "                 protvec_model = None,\n",
    "\n",
    "                 nodes_test = [], \n",
    "                 nodes_validation = [], \n",
    "\n",
    "                 edges_test = [], \n",
    "                 edges_validation = [], \n",
    "\n",
    "                 model_out_dir = None,\n",
    "\n",
    "                 debug = False):\n",
    "\n",
    "        '''\n",
    "         Class initialisation\n",
    "\n",
    "         Inputs : \n",
    "\n",
    "             Optional - one of two below\n",
    "                 interactions_location : String - Location of interactions file (CSV / Pickle)\n",
    "                 interactions : Pandas DataFrame - Interactions dataframe\n",
    "\n",
    "             interaction_y_name : String - Column name for true variable in interactions file\n",
    "\n",
    "             Optional - one of two below\n",
    "                 drugs_location : String - Location of drugs file (CSV / Pickle)\n",
    "                 drugs_dataframe : Pandas DataFrame - Drugs DataFrame\n",
    "             drug_inchi_name : String - Column name of field that contains the InChi Key \n",
    "             drug_smile_name : String - Column name of field that contains the chemical SMILE\n",
    "\n",
    "             Optional - one of two below\n",
    "                 targets_location : String - Location of targets file (CSV / Pickle)\n",
    "                 targets_dataframe : Pandas DataFrame - Targets DataFrame\n",
    "             target_seq_name : String - Column name of field that contains the amino acid sequence\n",
    "\n",
    "             Optional - one of two below\n",
    "                 mol2vec_location : String - Location of Mol2Vec model file\n",
    "                 mol2vec_model : Word2Vec - Word2Vec model\n",
    "\n",
    "             Optional - one of two below\n",
    "                 protvec_location : String - Location of ProtVec model file \n",
    "                 protvec_model : Pandas DataFrame - ProtVec model DataFrame\n",
    "\n",
    "             nodes_test : List - List of DataFrames of test set where all nodes must be unseen in the train set\n",
    "             nodes_validation : List - List of DataFrames of validation set where all nodes must be unseen in the train set\n",
    "\n",
    "             edges_test : List - List of DataFrames of test set where the rows must be unseen in the train set\n",
    "             edges_validation : List - List of DataFrames of validation set where the rows must be unseen in the train set\n",
    "\n",
    "             model_out_dir : String - Path to save trained models\n",
    "\n",
    "             debug : Bool - Flag to print debug lines\n",
    "\n",
    "        '''\n",
    "\n",
    "        # Set Variables\n",
    "        self.interactions_location = interactions_location\n",
    "        self.interactions = interactions\n",
    "        self.interaction_y_name = interaction_y_name\n",
    "        \n",
    "        self.absolute_negatives_location = absolute_negatives_location\n",
    "        self.absolute_negatives = absolute_negatives\n",
    "\n",
    "        self.drugs_location = drugs_location\n",
    "        self.drugs_dataframe = drugs_dataframe \n",
    "        self.drug_inchi_name = drug_inchi_name\n",
    "        self.drug_smile_name = drug_smile_name\n",
    "\n",
    "        self.targets_location = targets_location\n",
    "        self.targets_dataframe = targets_dataframe\n",
    "        self.target_seq_name = target_seq_name\n",
    "\n",
    "        self.mol2vec_location = mol2vec_location\n",
    "        self.mol2vec_model = mol2vec_model\n",
    "\n",
    "        self.protvec_location = protvec_location\n",
    "        self.protvec_model = protvec_model\n",
    "\n",
    "        self.nodes_test = nodes_test\n",
    "        self.nodes_validation = nodes_validation\n",
    "        self.edges_test = edges_test\n",
    "        self.edges_validation = edges_validation\n",
    "\n",
    "        self.model_out_dir = model_out_dir\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        # Read In Drugs \n",
    "        if type(self.drugs_dataframe) == type(None):\n",
    "            self.drugs_dataframe = self.read_input_files(self.drugs_location)\n",
    "\n",
    "        # Read In Targets\n",
    "        if type(self.targets_dataframe) == type(None):\n",
    "            self.targets_dataframe = self.read_input_files(self.targets_location)\n",
    "\n",
    "        # Create Drug Target Lists\n",
    "        self.drug_list = list(self.drugs_dataframe[self.drug_inchi_name])\n",
    "        self.target_list = list(self.targets_dataframe[self.target_seq_name])\n",
    "\n",
    "        # Read In Interactions File\n",
    "        if type(self.interactions) == type(None):\n",
    "            self.interactions = self.read_input_files(self.interactions_location)\n",
    "            \n",
    "        # Read In Absolute Negatives File\n",
    "        if type(self.absolute_negatives) == type(None):\n",
    "            if type(self.absolute_negatives_location) != type(None):\n",
    "                self.absolute_negatives = self.read_input_files(self.absolute_negatives_location)\n",
    "\n",
    "        # Column Name Assertions \n",
    "        assert self.drug_inchi_name in self.interactions.columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "        assert self.drug_inchi_name in self.drugs_dataframe.columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "\n",
    "        if self.nodes_test != []:\n",
    "            assert self.drug_inchi_name in self.nodes_test[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "            assert self.drug_inchi_name in self.nodes_validation[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "            assert self.drug_inchi_name in self.edges_test[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "            assert self.drug_inchi_name in self.edges_validation[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "\n",
    "        assert self.target_seq_name in self.interactions.columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "        assert self.target_seq_name in self.targets_dataframe.columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "\n",
    "        if self.nodes_test != []:\n",
    "            assert self.target_seq_name in self.nodes_test[0].columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "            assert self.target_seq_name in self.nodes_validation[0].columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "            assert self.target_seq_name in self.edges_test[0].columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "            assert self.target_seq_name in self.edges_validation[0].columns, \"Please ensure columns withAmino Acid Sequences have the same name across all dataframes\"\n",
    "\n",
    "\n",
    "    ###################################################\n",
    "    ############    General Functions      ############\n",
    "    ###################################################\n",
    "\n",
    "    # Read Input Files \n",
    "    def read_input_files(self, input_location):\n",
    "\n",
    "        '''\n",
    "        Reads in files into a dataframe given a file location. Currently works with CSV and Pickle files. \n",
    "\n",
    "        Inputs : \n",
    "            input_location : String - Location of file to read in - accepts only CSV and Pickle files\n",
    "        Outputs : \n",
    "            Pandas DatraFrame \n",
    "\n",
    "        '''\n",
    "\n",
    "        assert type(input_location) == type(\"\"), 'Location should be of type str'\n",
    "\n",
    "        if input_location.split('.')[-1] == 'pkl':\n",
    "            with open(input_location, 'rb') as file: \n",
    "                return pkl.load(file)\n",
    "\n",
    "        elif input_location.split('.')[-1] == 'csv':\n",
    "            return pd.read_csv(input_location)\n",
    "\n",
    "        else:\n",
    "            raise TypeError(\"Unknown input file type, only pkl and csv are supported\")\n",
    "\n",
    "    def sub_len(self, input_list):\n",
    "        '''\n",
    "        Returns length of sub-lists\n",
    "\n",
    "        Input :\n",
    "            input_list : List - List of lists\n",
    "\n",
    "        Output : \n",
    "            List of lenght of each sub list\n",
    "        '''\n",
    "        return [len(l) for l in input_list]\n",
    "\n",
    "    def create_interaction_dicts(self, interactions):\n",
    "\n",
    "        '''\n",
    "            Creates dictionaries for drugs and targets of the form \n",
    "                InchiKey : {Y = 0 : [AA Seqs], Y = 1 : [AA Seqs]} \n",
    "                and \n",
    "                AA Seq  : {Y = 0 : [InChi Keys], Y = 1 : [InChi Keys]} \n",
    "\n",
    "            Inputs : \n",
    "                interactions : Pandas DataFrame - Pandas dataframe of interactions\n",
    "\n",
    "            Outputs : \n",
    "                Dictionaries with InChi Key and AA Seq binding information as mentioned above\n",
    "        '''\n",
    "\n",
    "        drug_dict = {}\n",
    "        target_dict = {}\n",
    "\n",
    "        for i in tqdm(range(len(interactions))):\n",
    "\n",
    "            drug_id = interactions['InChiKey'].values[i]\n",
    "            target_id = interactions['target_aa_code'].values[i]\n",
    "            binding = interactions['Y'].values[i]\n",
    "\n",
    "            try:\n",
    "                drug_dict[drug_id]\n",
    "            except:\n",
    "                drug_dict[drug_id] = {}\n",
    "\n",
    "            try:\n",
    "                drug_dict[drug_id][binding].append(target_id)\n",
    "            except:\n",
    "                drug_dict[drug_id][binding] = [target_id]\n",
    "\n",
    "            try:\n",
    "                target_dict[target_id]\n",
    "            except:\n",
    "                target_dict[target_id] = {}\n",
    "\n",
    "            try:\n",
    "                target_dict[target_id][binding].append(drug_id)\n",
    "            except:\n",
    "                target_dict[target_id][binding] = [drug_id]\n",
    "\n",
    "        return drug_dict, target_dict\n",
    "\n",
    "    def create_adjacency(self, drug_dict, target_dict, full = True, include_negative = False):\n",
    "\n",
    "        '''\n",
    "            Creates adjacency matrix out of dictionaries with InChiKey and AA Seq binding info\n",
    "\n",
    "            Inputs : \n",
    "                drug_dict : Dictionary - Dict with InChiKey binding info\n",
    "                target_dict : Dictionary - Dict with AA Seq binding info\n",
    "                full : Bool - Boolean to determine whether to return a full adjacency matrix for a bipartite network\n",
    "                include_negative : Bool - Boolean to determine if negative interactions should be included as '-1' in the adjacency matrix\n",
    "            Outputs : \n",
    "                Adjacency matrix\n",
    "\n",
    "        '''\n",
    "\n",
    "        # Create Adjascency Matrix For Drugs x Amino Acids\n",
    "        drug_list = list(drug_dict.keys())\n",
    "        target_list = list(target_dict.keys())\n",
    "        number_of_drugs = len(list(drug_dict.keys()))\n",
    "        number_of_targets = len(list(target_dict.keys()))\n",
    "\n",
    "        adjascency_matrix = np.zeros((number_of_drugs, number_of_targets))\n",
    "\n",
    "        if include_negative == False: \n",
    "            for i in tqdm(range(number_of_drugs)):\n",
    "                for j in range(number_of_targets):\n",
    "\n",
    "                    try:\n",
    "                        if target_list[j] in drug_dict[drug_list[i]][1]:\n",
    "                            adjascency_matrix[i][j] = 1\n",
    "                    except: \n",
    "                        None\n",
    "\n",
    "                    try: \n",
    "                        if target_list[j] in drug_dict[drug_list[i]][0]:\n",
    "                            adjascency_matrix[i][j] = 0\n",
    "                    except: \n",
    "                        None\n",
    "\n",
    "        else : \n",
    "            for i in tqdm(range(number_of_drugs)):\n",
    "                for j in range(number_of_targets):\n",
    "\n",
    "                    try:\n",
    "                        if target_list[j] in drug_dict[drug_list[i]][1]:\n",
    "                            adjascency_matrix[i][j] = 1\n",
    "                    except: \n",
    "                        None\n",
    "\n",
    "                    try: \n",
    "                        if target_list[j] in drug_dict[drug_list[i]][0]:\n",
    "                            adjascency_matrix[i][j] = -1\n",
    "                    except: \n",
    "                        None\n",
    "\n",
    "        if full == False: \n",
    "            return adjascency_matrix\n",
    "\n",
    "        else: \n",
    "            # Create full bipartite adjacency matrix\n",
    "            true_adjacency_matrix_bipartite = np.block([\n",
    "                [np.zeros((len(drug_dict), len(drug_dict))), adjascency_matrix],\n",
    "                [adjascency_matrix.T, np.zeros((len(target_dict), len(target_dict)))]\n",
    "            ])\n",
    "            return true_adjacency_matrix_bipartite\n",
    "\n",
    "    def create_n_hop_negatives(self, interactions = None, path_lower_bound = 10, path_upper_bound = 16, max_hop = 16, show_plot = False, return_negatives = False):\n",
    "\n",
    "        '''\n",
    "            Creates a dataframe with pairs that are n hops away from each other conditional on bounds specified\n",
    "\n",
    "            Inputs : \n",
    "                interactions : Pandas DataFrame - Pandas Dataframe with drug target interactions\n",
    "                path_lower_bound : Integer - All hops equal to or above path_lower_bound and lower than path_upper_bound are considered negative \n",
    "                path_upper_bound : Integer - All hops equal to or above path_lower_bound and lower than path_upper_bound are considered negative \n",
    "                max_hop : Integer - Compute hops upto this value\n",
    "                show_plot : Bool - Plot histogram of hop distribution\n",
    "                return_negatives : Bool - Return negatives dataframe\n",
    "\n",
    "        '''\n",
    "\n",
    "        if type(interactions) == type(None):\n",
    "            print (\"No interaction file given, using train interactions instead.\")\n",
    "            interactions = self.interactions\n",
    "\n",
    "        # Create Drug and Target Dictionaries\n",
    "        drug_dict, target_dict = self.create_interaction_dicts(interactions)\n",
    "\n",
    "        # Create Adjacency Matrix For The Network From Above Dictionaries\n",
    "        adjacency = self.create_adjacency(drug_dict, target_dict)\n",
    "\n",
    "        # Create A List Of Degrees\n",
    "        degree = np.sum(adjacency, axis = 0) + 1e-2\n",
    "\n",
    "        num_nodes = adjacency.shape[0]\n",
    "\n",
    "        # Compute hops \n",
    "        higher_adjacency_matrix = np.zeros((num_nodes, num_nodes, max_hop + 1))\n",
    "\n",
    "        higher_adjacency_matrix[:,:,0] =  np.identity(num_nodes)\n",
    "\n",
    "        for i in tqdm(range(1, max_hop)):\n",
    "            higher_adjacency_matrix[:, :, i] = np.dot(higher_adjacency_matrix[:, :, i - 1], adjacency)\n",
    "\n",
    "        higher_adjacency_matrix[:, :, max_hop] = np.ones((num_nodes, num_nodes))\n",
    "        path_length = (higher_adjacency_matrix != 0).argmax(axis = 2)\n",
    "\n",
    "        # Plot\n",
    "        if show_plot: \n",
    "            plt.title(\"Path Lengths\")\n",
    "            plt.xlabel(\"Hop Distance\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.hist(path_length.flatten(), bins = list(range(0, max_hop + 1)))\n",
    "            plt.show()\n",
    "\n",
    "        # Get split points\n",
    "        drug_split = len(drug_dict)\n",
    "        target_split = len(target_dict)\n",
    "        drug_list = list(drug_dict)\n",
    "        target_list = list(target_dict)\n",
    "\n",
    "        # Create Max Hop Negatives\n",
    "        dataframe = []\n",
    "        for i, j in tqdm(zip(*np.where((path_length >= path_lower_bound) & (path_length < path_upper_bound)))):\n",
    "            if i < drug_split and j >= drug_split:\n",
    "                dataframe.append([drug_list[i], target_list[j - drug_split], 0])\n",
    "\n",
    "        self.negatives = pd.DataFrame(dataframe)\n",
    "        self.negatives.columns = [self.drug_inchi_name, self.target_seq_name, self.interaction_y_name]\n",
    "\n",
    "        if return_negatives:\n",
    "            return self.negatives\n",
    "\n",
    "    def create_test_splits(self, interactions = None, frac = 0.15, num_splits = 5, true_negatives_df = None, seed = 2021, update_dataframes = True, return_dataframes = False, debug = None):\n",
    "\n",
    "        '''\n",
    "        interactions : Pandas DataFrame - Pandas Dataframe with drug target interactions\n",
    "        frac : Flaot -  Fraction of interactions to be considered for test and validation\n",
    "        num_splits : Integer - Number of splits to create for the K fold cross validation process\n",
    "        seed : Integer - Random seed initialisation\n",
    "        update_dataframes : Bool - Update class variable with test and validation sets \n",
    "        return_dataframes : Bool - Return test and validation sets\n",
    "        debug : Bool - Print debug info\n",
    "\n",
    "        '''\n",
    "\n",
    "        if type(debug) == type(None):\n",
    "            debug = self.debug\n",
    "\n",
    "        if type(interactions) == type(None):\n",
    "            print (\"No interaction file given, using train interactions instead.\")\n",
    "            interactions = self.interactions\n",
    "\n",
    "        # Initial parameters\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        targets = self.targets_dataframe\n",
    "        num_in_split = targets.shape[0] // num_splits\n",
    "\n",
    "        # Shuffle target list\n",
    "        target_list = list(targets[self.target_seq_name])\n",
    "        np.random.shuffle(target_list)\n",
    "\n",
    "        # Unseen Targets \n",
    "        # Create Multiple Sets Of Unseen Targets\n",
    "        unseen_target_sets = np.split(np.array(target_list),\n",
    "                                      [num_in_split * i for i in range(1, num_splits)])\n",
    "\n",
    "        # Create Seen Target Sets For Each Unseen Target Set Above\n",
    "        seen_target_sets = [set(targets[self.target_seq_name]).difference(unseen_targets) for unseen_targets in unseen_target_sets]\n",
    "\n",
    "        if debug : \n",
    "            print (\"Number Of Unseen Targets In Each Set : \", self.sub_len(unseen_target_sets))\n",
    "            print (\"Number Of Seen Targets In Each Set : \", self.sub_len(seen_target_sets))\n",
    "\n",
    "        # Create Set Of Seen Target DataFrames\n",
    "        seen_target_pos_df_sets = [interactions[interactions[self.target_seq_name].isin(seen_targets)] \n",
    "                                   for seen_targets in seen_target_sets]\n",
    "\n",
    "        # Create Set Of Unseen Target DataFrames\n",
    "        unseen_target_pos_df_sets = [interactions[interactions[self.target_seq_name].isin(unseen_targets)] \n",
    "                                     for unseen_targets in unseen_target_sets]\n",
    "\n",
    "        # Make DataFrames Prettier\n",
    "        seen_target_pos_df_sets = [seen_target_df[[self.drug_inchi_name, self.target_seq_name, self.interaction_y_name]] for seen_target_df in seen_target_pos_df_sets]\n",
    "        unseen_target_pos_df_sets = [unseen_target_df[[self.drug_inchi_name, self.target_seq_name, self.interaction_y_name]] for unseen_target_df in unseen_target_pos_df_sets]\n",
    "\n",
    "        if debug: \n",
    "            print (\"Length Of Unseen Target DataFrames (Positives Only) : \", self.sub_len(unseen_target_pos_df_sets))\n",
    "\n",
    "        unseen_targets_df_sets = []\n",
    "\n",
    "        for idx, unseen_target_df in enumerate(unseen_target_pos_df_sets):\n",
    "\n",
    "            # Get Random Negative DataFrame\n",
    "            neg_df = self.negatives[self.negatives[self.target_seq_name].isin(unseen_target_sets[idx])]\n",
    "\n",
    "            # Figure Out Sample Ratio\n",
    "            sample_ratio = max(self.sub_len(unseen_target_pos_df_sets)) / neg_df.shape[0]\n",
    "\n",
    "            # Sample Negatives\n",
    "            neg_df = neg_df.sample(frac = sample_ratio, replace = False)\n",
    "\n",
    "            # Concatenate With Random Negatives\n",
    "            unseen_target_df = pd.concat([unseen_target_df, neg_df])\n",
    "\n",
    "            # Shuffle \n",
    "            unseen_target_df = unseen_target_df.sample(frac = 1.0, replace = False)\n",
    "\n",
    "            # Append\n",
    "            unseen_targets_df_sets.append(unseen_target_df)\n",
    "\n",
    "        if debug: \n",
    "            print (\"Length Of Unseen Targets DataFrames (Complete) : \", self.sub_len(unseen_targets_df_sets))\n",
    "\n",
    "        # Unseen Edges\n",
    "        unseen_edges_df_sets = []\n",
    "\n",
    "        for idx, (seen_target_df, seen_targets) in enumerate(zip(seen_target_pos_df_sets, seen_target_sets)):\n",
    "\n",
    "            # Get Random Negative DataFrame\n",
    "            neg_df = self.negatives[self.negatives[self.target_seq_name].isin(seen_target_sets[idx])]\n",
    "\n",
    "            # Sample From The Seen Target DataFrame\n",
    "            unseen_edges_pos_df = seen_target_df.sample(frac = frac, replace = False).reset_index(drop = True)\n",
    "\n",
    "            # Figure Out Sample Ratio\n",
    "            sample_ratio = unseen_edges_pos_df.shape[0] / neg_df.shape[0]\n",
    "\n",
    "            # Sample Negatives\n",
    "            neg_df = neg_df.sample(frac = sample_ratio, replace = False)\n",
    "\n",
    "            # Concatenate With Random Negatives\n",
    "            unseen_edges_df = pd.concat([unseen_edges_pos_df, neg_df])\n",
    "\n",
    "            # Shuffle \n",
    "            unseen_edges_df = unseen_edges_df.sample(frac = 1.0, replace = False)\n",
    "\n",
    "            # Append\n",
    "            unseen_edges_df_sets.append(unseen_edges_df)\n",
    "\n",
    "        if debug: \n",
    "            print (\"Length Of Unseen Edges DataFrames (Complete) : \", self.sub_len(unseen_edges_df_sets))\n",
    "\n",
    "        # Target validation sets\n",
    "        nodes_test = []\n",
    "        nodes_validation = []\n",
    "\n",
    "        for dataframe in tqdm(unseen_targets_df_sets):\n",
    "\n",
    "            split_point = dataframe.shape[0] // 2\n",
    "            split = np.split(dataframe, [split_point])\n",
    "            nodes_test.append(split[0])\n",
    "            nodes_validation.append(split[1])\n",
    "        if debug :\n",
    "            print (\"Unseen Nodes/Targets \")\n",
    "            print (\"Shapes Of Validation Sets : \", self.sub_len(nodes_validation))\n",
    "            print (\"Shapes Of Test Sets : \", self.sub_len(nodes_test))\n",
    "\n",
    "        # Edges Validation\n",
    "        edges_test = []\n",
    "        edges_validation = []\n",
    "\n",
    "        for dataframe in tqdm(unseen_edges_df_sets):\n",
    "\n",
    "            split_point = dataframe.shape[0] // 2\n",
    "            split = np.split(dataframe, [split_point])\n",
    "            edges_test.append(split[0])\n",
    "            edges_validation.append(split[1])\n",
    "        if debug : \n",
    "            print (\"Unseen Edges\")\n",
    "            print (\"Shapes Of Validation Sets : \", self.sub_len(edges_validation))\n",
    "            print (\"Shapes Of Test Sets : \", self.sub_len(edges_test))\n",
    "\n",
    "        if type(self.absolute_negatives) != type(None) and type(true_negatives_df) == type(None):\n",
    "            true_negatives_df = self.absolute_negatives\n",
    "        \n",
    "        # Update with true negatives\n",
    "        if type(true_negatives_df) != type(None):\n",
    "\n",
    "            # Ensure these drugs and targets are part of the drugs/targets dataframes\n",
    "            # Only keep needed columns in drugs and targets dataframe\n",
    "            self.drugs_dataframe = self.drugs_dataframe[[self.drug_inchi_name, self.drug_smile_name]]\n",
    "            self.targets_dataframe = self.targets_dataframe[[self.target_seq_name]]\n",
    "\n",
    "            # Concatenate with absolute negative data\n",
    "            self.drugs_dataframe = pd.concat([self.drugs_dataframe, true_negatives_df[[self.drug_inchi_name, self.drug_smile_name]]]).drop_duplicates(keep = \"first\")\n",
    "            self.targets_dataframe = pd.concat([self.targets_dataframe, true_negatives_df[[self.target_seq_name]]]).drop_duplicates(keep = \"first\")\n",
    "\n",
    "            # Recreate drug and target lists \n",
    "            self.drug_list = list(self.drugs_dataframe[self.drug_inchi_name])\n",
    "            self.target_list = list(self.targets_dataframe[self.target_seq_name])\n",
    "            \n",
    "            # Shuffle the dataframe\n",
    "            true_negatives_df = true_negatives_df.sample(frac = 1)\n",
    "\n",
    "            # Split into equal chunks \n",
    "            split_ratio = true_negatives_df.shape[0] // len(nodes_test)\n",
    "            splits = np.split(true_negatives_df, [i * split_ratio for i in range(len(nodes_test))])\n",
    "\n",
    "            # Add into test sets \n",
    "            for idx in range(len(nodes_test)):\n",
    "                nodes_test[idx] = pd.concat([nodes_test[idx], splits[idx]])\n",
    "\n",
    "        if update_dataframes:\n",
    "            self.nodes_test = nodes_test\n",
    "            self.nodes_validation = nodes_validation\n",
    "            self.edges_test = edges_test\n",
    "            self.edges_validation = edges_validation\n",
    "\n",
    "        if return_dataframes : \n",
    "            return nodes_test, nodes_validation, edges_test, edges_validation\n",
    "\n",
    "    def create_train_sets(self, unseen_nodes_flag = True, data_leak_check = True):   \n",
    "\n",
    "        '''\n",
    "            Creates train sets by ensuring exclusitivity between test and validation sets. \n",
    "\n",
    "            Inputs : \n",
    "                unseen_nodes_flag : Bool - Ensures drugs and targets are both unseen in the train set if true. Only ensures unseen targets if false/\n",
    "                data_leak_check : Bool - Performs sanity checks to ensure no data leakage between train / validation and test sets\n",
    "\n",
    "        ''' \n",
    "\n",
    "        self.train_sets = []\n",
    "        self.train_pos_neg_ratio = []\n",
    "\n",
    "        for i in tqdm(range(len(self.nodes_test))):\n",
    "\n",
    "            # Unseen Targets\n",
    "            unseen_targets = list(set(self.nodes_test[i][self.target_seq_name])) + list(set(self.nodes_validation[i][self.target_seq_name]))\n",
    "\n",
    "            # Unseen Drugs\n",
    "            unseen_drugs = list(set(self.nodes_test[i][self.drug_inchi_name])) + list(set(self.nodes_validation[i][self.drug_inchi_name]))\n",
    "\n",
    "            # Seen Targets\n",
    "            seen_targets = set(self.targets_dataframe[self.target_seq_name]).difference(unseen_targets)\n",
    "\n",
    "            # Seen Drugs\n",
    "            seen_drugs = set(drugs[self.drug_inchi_name]).difference(unseen_drugs)\n",
    "\n",
    "            # Seen Targets \n",
    "            seen_target_df = self.interactions[self.interactions[self.target_seq_name].isin(seen_targets)]\n",
    "            seen_target_df = seen_target_df[[self.drug_inchi_name, self.target_seq_name, self.interaction_y_name]]\n",
    "\n",
    "            # Create dataframe with train interactions\n",
    "            # pd.concat + drop duplicates amounts to a set interesection\n",
    "            train_interactions = pd.concat([seen_target_df,\n",
    "                                            self.edges_test[i],\n",
    "                                            self.edges_test[i],\n",
    "                                            self.edges_validation[i],\n",
    "                                            self.edges_validation[i]]).drop_duplicates(keep = False)\n",
    "\n",
    "            # Ensure unseen nodes if flag is on, else train sets only satisfy unseen targets criteria\n",
    "            if unseen_nodes_flag: \n",
    "                # Ensure Unseen Drugs\n",
    "                train_interactions = train_interactions.reset_index(drop = True)\n",
    "                drop_index = []\n",
    "                for idx, row in tqdm(train_interactions.iterrows()):\n",
    "                    if row[self.drug_inchi_name] in unseen_drugs:\n",
    "                        drop_index.append(idx)\n",
    "                train_interactions.drop(train_interactions.index[drop_index], inplace = True)\n",
    "\n",
    "            self.train_sets.append(train_interactions)\n",
    "            self.train_pos_neg_ratio.append(1 / np.divide(*np.array(train_interactions['Y'].value_counts().values)))\n",
    "\n",
    "        # Sanity check section\n",
    "        if data_leak_check:\n",
    "            for i in range(len(self.nodes_test)):\n",
    "\n",
    "                print (\"Set : \", i)\n",
    "\n",
    "                # No Overlap Between Unseen Nodes and Train\n",
    "                unseen_targets = list(set(self.nodes_test[i][self.target_seq_name])) + list(set(self.nodes_validation[i][self.target_seq_name]))\n",
    "                print (\"Train - Test - Validation Overlap For Unseen Targets : \", len(list(set(self.train_sets[i][self.target_seq_name]).intersection(unseen_targets))))\n",
    "\n",
    "                if unseen_nodes_flag:\n",
    "                    # No overlap Between Drugs\n",
    "                    unseen_drugs = list(set(self.nodes_test[i][self.drug_inchi_name])) + list(set(self.nodes_validation[i][self.drug_inchi_name]))\n",
    "                    print (\"Train - Test - Validation Overlap For Unseen Drugs : \", len(list(set(self.train_sets[i][self.drug_inchi_name]).intersection(unseen_drugs))))\n",
    "\n",
    "\n",
    "                # No Overlap Between Unseen Edges and Train\n",
    "                train_edges = list(zip(list(self.train_sets[i][self.drug_inchi_name]), list(self.train_sets[i][self.target_seq_name])))\n",
    "                temp_df = pd.concat([self.edges_test[i], self.edges_validation[i]])\n",
    "                test_edges = list(zip(list(temp_df[self.drug_inchi_name]), list(temp_df[self.target_seq_name])))\n",
    "                train_edges = set(train_edges)\n",
    "                test_edges = set(test_edges)\n",
    "                print (\"Train - Test - Validation Overlap For Unseen Edges : \", len(list(train_edges.intersection(test_edges))))\n",
    "\n",
    "                print (\"Train Set : \", self.train_sets[i].shape)\n",
    "                print (\"Nodes Test : \", self.nodes_test[i].shape)\n",
    "                print (\"Nodes Val : \", self.nodes_validation[i].shape)\n",
    "                print (\"Edge Test : \", self.edges_test[i].shape)\n",
    "                print (\"Edge Val : \", self.edges_validation[i].shape)\n",
    "                print (\"Positive / Negatative Ratio : \", self.train_pos_neg_ratio[i])\n",
    "                print (\"\")\n",
    "\n",
    "    def dataframe_to_embed_array(self, interactions_df, drug_list, target_list, drug_embed_len, normalized_drug_embeddings = None, normalized_target_embeddings = None, include_true_label = True):\n",
    "\n",
    "        '''\n",
    "            Creates numpy arrays that can be fed into the model from interaction dataframes. \n",
    "\n",
    "            Inputs : \n",
    "                interactions_df : Pandas DataFrame - Pandas dataframe containing interactions\n",
    "                drug_list : List - List of drug InChi Keys\n",
    "                target_list : List - List of target AA Sequences\n",
    "                drug_embed_len : Integer - Length of drug embedding vector\n",
    "\n",
    "            Outputs : \n",
    "                X_0 : Numpy Array - Array with target vectors\n",
    "                X_1 : Numpy Array - Array with drug vectors\n",
    "                Y :  Numpy Array - Array with true labels\n",
    "        '''\n",
    "\n",
    "        X_0_list = []\n",
    "        X_1_list = []\n",
    "\n",
    "        if type(normalized_target_embeddings) == type(None):\n",
    "            normalized_target_embeddings = self.normalized_target_embeddings\n",
    "\n",
    "        if type(normalized_drug_embeddings) == type(None):\n",
    "            normalized_drug_embeddings = self.normalized_drug_embeddings\n",
    "\n",
    "        skipped_drugs = 0\n",
    "\n",
    "        # Iterate over all rows in dataframe\n",
    "        for idx, row in interactions_df.iterrows():\n",
    "\n",
    "            # Get InChiKey and AA Sequence\n",
    "            drug = row[self.drug_inchi_name]\n",
    "            target = row[self.target_seq_name]\n",
    "\n",
    "            # Get drug index for this drug in drug_list\n",
    "            try:\n",
    "                drug_index = drug_list.index(drug)\n",
    "            except: \n",
    "                drug_index = -1\n",
    "\n",
    "            # Get target index for this target in target_list\n",
    "            target_index = target_list.index(target)\n",
    "\n",
    "            # Index into target embedding array and add to X_0\n",
    "            X_0_list.append(normalized_target_embeddings[target_index])\n",
    "\n",
    "            # If drug index not found, add random vector to X_1\n",
    "            if drug_index == -1:\n",
    "                X_1_list.append(np.random.randn(drug_embed_len,))\n",
    "                skipped_drugs = skipped_drugs + 1\n",
    "            else:\n",
    "                # Index into drug embedding array and add to X_1\n",
    "                try:\n",
    "                    X_1_list.append(normalized_drug_embeddings[drug_index])\n",
    "                # If drug index not found, add random vector to X_1\n",
    "                except: \n",
    "                    X_1_list.append(np.random.randn(drug_embed_len,))\n",
    "                    skipped_drugs = skipped_drugs + 1\n",
    "\n",
    "        # Convert lists to arrays\n",
    "        X_0 = np.array(X_0_list)\n",
    "        X_1 = np.array(X_1_list)\n",
    "\n",
    "        if self.debug:\n",
    "            print (\"Number of drugs skipped : \", skipped_drugs)\n",
    "\n",
    "        if include_true_label:\n",
    "            Y = np.array(list(interactions_df['Y']))\n",
    "            return X_0, X_1, Y\n",
    "        else: \n",
    "            return X_0, X_1\n",
    "\n",
    "    def get_validation_results(self, model_name = None, version_number = None, show_plots = True, plot_title = None, num_cols = 2, plot_height = 1500, plot_width = 1500, write_plot_to_html = False, plot_dir = None, plot_name = None):\n",
    "\n",
    "        '''\n",
    "            Computes validation results \n",
    "\n",
    "            Inputs : \n",
    "                model_name : String - Key of model used while trainig. If None, class variable will be picked up\n",
    "                version_number : Integer - Version number for the model \n",
    "                show_plots : Bool - Show learning curve plots\n",
    "                plot_title : String - Title for learning curve plots\n",
    "                num_cols : Integer - Number of columns in learning curve plot grid - rows are automatically calculated\n",
    "                plot_height : Integer - Plot height in pixels\n",
    "                plot_width : Integer - Plot width in pixels\n",
    "                write_plot_to_html : Bool - Save plot to disk in HTML format (interactive)\n",
    "                plot_dir : String - Path to save plot \n",
    "                plot_name : String - Name of saved plot\n",
    "\n",
    "            Outputs : \n",
    "                Updates optimal validation epoch to self.optimal_validation_model\n",
    "\n",
    "        '''\n",
    "\n",
    "        self.averaged_results = {}\n",
    "\n",
    "        if type(model_name) != type(None) and type(version_number) == type(None):\n",
    "            raise ValueError (\"Please enter a version number for this model\")\n",
    "\n",
    "        if type(model_name) == type(None):\n",
    "            model_name = list(self.results.keys())[0]\n",
    "        else: \n",
    "            model_name = model_name + '_v' + str(version_number)\n",
    "\n",
    "        num_rows = (len(self.train_sets) // num_cols) + (len(self.train_sets) % num_cols)\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows = num_rows, cols = num_cols,\n",
    "            subplot_titles = [' ' for _ in range(num_rows * num_cols)])\n",
    "\n",
    "        row_counter = 1\n",
    "        col_counter = 1\n",
    "\n",
    "        # Get length of the x axis to ensure avergaes make sense \n",
    "        x_length = [len(self.results[model_name][run]['val_auc_ut']) for run in self.results[model_name].keys()]\n",
    "        # Pick the length that is most common to compute aligned averages\n",
    "        x_length = list(Counter(x_length))[0]\n",
    "\n",
    "        for run in self.results[model_name].keys():\n",
    "\n",
    "            # Plot legend only once\n",
    "            if run == 0:\n",
    "                legend = True\n",
    "            else: \n",
    "                legend = False\n",
    "\n",
    "            # X axis list\n",
    "            x_list = [x for x in range(len(self.results[model_name][run]['val_auc_ut']))]\n",
    "\n",
    "            # Ensure lengths match up \n",
    "            if len(x_list) == x_length:\n",
    "\n",
    "                # Save validation AUC averaged scores for Unseen Nodes\n",
    "                if 'val_auc_ut' in self.averaged_results:\n",
    "                    self.averaged_results['val_auc_ut'] = self.averaged_results['val_auc_ut'] + np.array(self.results[model_name][run]['val_auc_ut']).reshape(-1, 1)\n",
    "                elif 'val_auc_ut' not in self.averaged_results: \n",
    "                    self.averaged_results['val_auc_ut'] = np.array(self.results[model_name][run]['val_auc_ut']).reshape(-1, 1)\n",
    "\n",
    "                # Save validation AUC averaged scores for Unseen Edges\n",
    "                if 'val_auc_ue' in self.averaged_results:\n",
    "                    self.averaged_results['val_auc_ue'] = self.averaged_results['val_auc_ue'] + np.array(self.results[model_name][run]['val_auc_ue']).reshape(-1, 1)\n",
    "                elif 'val_auc_ue' not in self.averaged_results: \n",
    "                    self.averaged_results['val_auc_ue'] = np.array(self.results[model_name][run]['val_auc_ue']).reshape(-1, 1)\n",
    "\n",
    "                # Save validation AUP averaged scores for Unseen Nodes\n",
    "                if 'val_aup_ut' in self.averaged_results:\n",
    "                    self.averaged_results['val_aup_ut'] = self.averaged_results['val_aup_ut'] + np.array(self.results[model_name][run]['val_aup_ut']).reshape(-1, 1)\n",
    "                elif 'val_aup_ut' not in self.averaged_results: \n",
    "                    self.averaged_results['val_aup_ut'] = np.array(self.results[model_name][run]['val_aup_ut']).reshape(-1, 1)\n",
    "\n",
    "                # Save validation AUP averaged scores for Unseen Edges\n",
    "                if 'val_aup_ue' in self.averaged_results:\n",
    "                    self.averaged_results['val_aup_ue'] = self.averaged_results['val_aup_ue'] + np.array(self.results[model_name][run]['val_aup_ue']).reshape(-1, 1)\n",
    "                elif 'val_aup_ue' not in self.averaged_results: \n",
    "                    self.averaged_results['val_aup_ue'] = np.array(self.results[model_name][run]['val_aup_ue']).reshape(-1, 1)\n",
    "\n",
    "            if show_plots:\n",
    "                # Plot validation AUC for Unseen Nodes    \n",
    "\n",
    "\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_auc_ut'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUC',\n",
    "                                         line_color = 'deepskyblue',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter )\n",
    "\n",
    "\n",
    "                # Plot validation AUC for Unseen Edges\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_auc_ue'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUC',\n",
    "                                         line_color = 'blue',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter )\n",
    "\n",
    "\n",
    "\n",
    "                # Plot validation AUP for Unseen Nodes\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_aup_ut'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUP',\n",
    "                                         line_color = 'red',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter )\n",
    "\n",
    "\n",
    "                # Plot validation AUP for Unseen Edges\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_aup_ue'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUP',\n",
    "                                         line_color = 'green',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter)\n",
    "\n",
    "\n",
    "                fig.update_xaxes(title_text = \"Epochs * Chunks\", row = row_counter, col = col_counter)\n",
    "                fig.update_yaxes(title_text = \"Performance\", row = row_counter, col = col_counter)\n",
    "                fig.layout.annotations[run]['text'] = model_name + \" Run \" + str(run)\n",
    "\n",
    "                if col_counter == num_cols: \n",
    "                    col_counter = 1\n",
    "                    row_counter = row_counter + 1\n",
    "                else: \n",
    "                    col_counter = col_counter + 1\n",
    "\n",
    "\n",
    "\n",
    "            # Averaged Results Plot\n",
    "            avg_fig = go.Figure()\n",
    "\n",
    "            x_list = [x for x in range(len(self.averaged_results['val_auc_ut']))]\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_auc_ut'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUC',\n",
    "                                         line_color = 'deepskyblue'),\n",
    "                         )\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_auc_ue'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUC',\n",
    "                                         line_color = 'blue'),\n",
    "                         )\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_aup_ut'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUP',\n",
    "                                         line_color = 'red'),\n",
    "                         )\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_aup_ue'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUP',\n",
    "                                         line_color = 'green'),\n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Optimal epoch\n",
    "        perf = np.zeros((self.averaged_results['val_aup_ue'].shape[0], 4))\n",
    "        ut_c = 0\n",
    "        ut_p = 1\n",
    "        ue_c = 2\n",
    "        ue_p = 3\n",
    "\n",
    "        perf[:, ut_c] = self.averaged_results['val_auc_ut'].ravel()\n",
    "        perf[:, ut_p] = self.averaged_results['val_aup_ut'].ravel()\n",
    "        perf[:, ue_c] = self.averaged_results['val_auc_ue'].ravel()\n",
    "        perf[:, ue_p] = self.averaged_results['val_aup_ue'].ravel()\n",
    "        perf = perf / self.averaged_results['val_aup_ue'].shape[0]\n",
    "\n",
    "        # UT AUC + UE AUC\n",
    "        edge_target = np.argmax(np.sum(perf[:, [ut_c, ue_c]], axis = 1))\n",
    "\n",
    "        # UT AUC + UT AUP\n",
    "        target_only = np.argmax(np.sum(perf[:, [ut_c, ut_p]], axis = 1))\n",
    "\n",
    "        # UE AUC + UE AUP\n",
    "        edge_only = np.argmax(np.sum(perf[:, [ue_c, ue_p]], axis = 1))\n",
    "\n",
    "        print (\"(Epoch * Chunk) With Highest Unseen Node and Edge Score : \", edge_target)\n",
    "        print (\"(Epoch * Chunk) With Highest Unseen Node Score : \", target_only)\n",
    "        print (\"(Epoch * Chunk) With Highest Unseen Edge Score : \", edge_target)\n",
    "\n",
    "        ut_auc = []\n",
    "        ut_aup = []\n",
    "        ue_auc = []\n",
    "        ue_aup = []\n",
    "\n",
    "        model_key = model_name\n",
    "        best_model = edge_target\n",
    "\n",
    "        for run in self.results[model_key].keys():\n",
    "\n",
    "            ut_auc.append(self.results[model_key][run]['val_auc_ut'][best_model])\n",
    "            ut_aup.append(self.results[model_key][run]['val_aup_ut'][best_model])\n",
    "            ue_auc.append(self.results[model_key][run]['val_auc_ue'][best_model])\n",
    "            ue_aup.append(self.results[model_key][run]['val_aup_ue'][best_model])\n",
    "\n",
    "        print (\"Validation Performance\")\n",
    "        print (\"Best Model Suffix : \", self.model_name_index[model_name][best_model])\n",
    "        print (\"Unseen Node AUC : \", np.mean(ut_auc), \"+/-\", np.std(ut_auc))\n",
    "        print (\"Unseen Node AUP : \", np.mean(ut_aup), \"+/-\", np.std(ut_aup))\n",
    "        print (\"Unseen Edges AUC : \", np.mean(ue_auc), \"+/-\", np.std(ue_auc))\n",
    "        print (\"Unseen Edges AUP : \", np.mean(ue_aup), \"+/-\", np.std(ue_aup))\n",
    "\n",
    "\n",
    "        try: \n",
    "            self.optimal_validation_model\n",
    "        except: \n",
    "            self.optimal_validation_model = {}\n",
    "\n",
    "        self.optimal_validation_model[model_name] = best_model\n",
    "\n",
    "\n",
    "        if show_plots:\n",
    "            fig.update_layout(title_text = plot_title, \n",
    "                                  height = plot_height,\n",
    "                                  width = plot_width,\n",
    "                                  showlegend = True)\n",
    "            fig.show()\n",
    "\n",
    "            avg_fig.update_layout(title_text = plot_title + \" - Averaged Results Across \" + str(len(x_list)) + \" Runs\", \n",
    "                              xaxis_title_text = 'Epochs * Chunks',\n",
    "                              yaxis_title_text = 'Performance',\n",
    "                              showlegend = True)\n",
    "            avg_fig.show()\n",
    "\n",
    "            if write_plot_to_html:\n",
    "                fig.write_html(plot_dir.rstrip('/') + plot_name + '_k_fold_split_plots.html')\n",
    "                avg_fig.write_html(plot_dir.rstrip('/') + plot_name + '_averaged_results_plots.html')\n",
    "\n",
    "    def get_fold_averaged_prediction_results(self, model_name = None, version_number = None, model_paths = [], optimal_validation_model = None, test_sets = [], get_drug_embed = False, get_target_embed = True,  drug_filter_list = [], target_filter_list = [], return_dataframes = False):\n",
    "\n",
    "        '''\n",
    "            Computes test results, but averages predictions for each pair across all K folds\n",
    "            Inputs : \n",
    "                model_name : String - Key of model used while trainig. If None, class variable will be picked up\n",
    "                version_number : Integer - Version number of model trained \n",
    "                model_paths : List - List of complete paths to external models \n",
    "                optimal_validation_model : Integer - Index of optimal epoch to use \n",
    "                test_sets : List - List of test set dataframes \n",
    "                get_drug_embed : Bool - If prediction dataset has drugs that completely overlap with train / test, then set to false, else set to true to generate embeddings\n",
    "                get_target_embed : Bool - If prediction dataset has targets that completely overlap with train / test, then set to false, else set to true to generate embeddings \n",
    "                drug_filter_list : List - List of InChi keys to filter and test on \n",
    "                target_filter_list : List - List of AA Sequences to filter and test on \n",
    "        '''\n",
    "\n",
    "        # Initialise dictionary\n",
    "        try: \n",
    "            self.fold_test_results\n",
    "        except: \n",
    "            self.fold_test_results = {}\n",
    "\n",
    "        if type(model_name) != type(None) and type(version_number) == type(None):\n",
    "\n",
    "            raise ValueError(\"Please enter a version number with the model name\")\n",
    "\n",
    "        if type(model_name) == type(None):\n",
    "                try:\n",
    "                    model_name = list(self.results.keys())[0]\n",
    "                except: \n",
    "                    model_name = \"\"\n",
    "\n",
    "        else: \n",
    "            model_name = model_name + \"_v\" + str(version_number)\n",
    "\n",
    "        if model_paths == []:\n",
    "            if type(optimal_validation_model) == type(None):    \n",
    "                optimal_validation_model = self.optimal_validation_model[model_name]\n",
    "\n",
    "                for model_run_number in range(len(self.train_sets)):\n",
    "\n",
    "                    model_prefix = \"_\".join(os.listdir(self.model_out_dir[model_name].rstrip('/') + '/Run_' + str(model_run_number))[0].split('_')[:-4])\n",
    "                    model_suffix = self.model_name_index[model_name][optimal_validation_model]\n",
    "                    model_location = self.model_out_dir[model_name].rstrip('/') + '/Run_' + str(model_run_number) + '/' + model_prefix + model_suffix\n",
    "\n",
    "                    model_paths.append(model_location)\n",
    "\n",
    "\n",
    "        if model_name not in self.fold_test_results.keys():\n",
    "            self.fold_test_results[model_name] = {}\n",
    "\n",
    "        if test_sets == []:\n",
    "            print (\"No test set given, predicting on class variable\")\n",
    "            test_sets = self.nodes_test\n",
    "\n",
    "        # Create list to hold predictions across folds \n",
    "        prediction_unseen_targets = {'model_' + str(x) : ['' for _ in range(len(test_sets))] for x in range(len(model_paths))}\n",
    "        # true_unseen_targets = {'model_' + str(x) : ['' for _ in range(len(test_sets))] for x in range(len(model_paths))}\n",
    "\n",
    "\n",
    "\n",
    "        # Iterate over all models \n",
    "        for model_run_number in range(len(model_paths)):\n",
    "\n",
    "            model_location = model_paths[model_run_number]\n",
    "\n",
    "            print (\"Testing on model : \", model_location)\n",
    "            model = load_model(model_location)\n",
    "\n",
    "            # Iterate over all sets \n",
    "            for sets_run_number in range(len(test_sets)):\n",
    "\n",
    "                drug_embed_len = self.normalized_drug_embeddings[0].shape[0]\n",
    "\n",
    "                filtered_nodes_test = test_sets[sets_run_number]\n",
    "\n",
    "\n",
    "                if drug_filter_list != [] and target_filter_list != []:\n",
    "                    filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.drug_inchi_name].isin(drug_filter_list)) & (filtered_nodes_test[self.target_seq_name].isin(target_filter_list))]\n",
    "\n",
    "                elif drug_filter_list != [] and target_filter_list == []:\n",
    "                    filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.drug_inchi_name].isin(drug_filter_list))]\n",
    "\n",
    "                elif drug_filter_list == [] and target_filter_list != []:\n",
    "                    filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.target_seq_name].isin(target_filter_list))]\n",
    "\n",
    "                else: \n",
    "                    None\n",
    "                    \n",
    "                print (\"filtered_nodes_test : \", filtered_nodes_test.shape)\n",
    "                print (\"Drugs : \", len(list(set(filtered_nodes_test[self.drug_inchi_name]))))\n",
    "                print (\"Targets : \", len(list(set(filtered_nodes_test[self.target_seq_name]))))\n",
    "\n",
    "                # if sets_run_number not in self.fold_test_results[model_name].keys(): \n",
    "                self.fold_test_results[model_name][sets_run_number] = filtered_nodes_test\n",
    "\n",
    "                # Get embeddings for prediction sets\n",
    "                if get_target_embed: \n",
    "                    pred_targets_dataframe = self.get_protvec_embeddings(prediction_interactions = filtered_nodes_test,\n",
    "                                                                         embedding_dimension = 100,\n",
    "                                                                         replace_dataframe = False,\n",
    "                                                                         return_normalisation_conststants = False,\n",
    "                                                                         delimiter = '\\t')\n",
    "                else: \n",
    "                    pred_targets_dataframe = self.targets_dataframe[self.targets_dataframe[self.target_seq_name].isin(list(filtered_nodes_test[self.target_seq_name]))]\n",
    "                    print (\"pred_targets_dataframe : \", pred_targets_dataframe.shape)\n",
    "\n",
    "                pred_target_list = list(pred_targets_dataframe[self.target_seq_name])\n",
    "                pred_normalized_target_embeddings = np.array(list(pred_targets_dataframe['normalized_embeddings']))\n",
    "\n",
    "\n",
    "                if get_drug_embed: \n",
    "                    pred_drugs_dataframe = self.get_mol2vec_embeddings(prediction_interactions = filtered_nodes_test,\n",
    "                                                                       embedding_dimension = 300,\n",
    "                                                                       replace_dataframe = False,\n",
    "                                                                       return_normalisation_conststants = False)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                else: \n",
    "                    pred_drugs_dataframe = self.drugs_dataframe[self.drugs_dataframe[self.drug_inchi_name].isin(list(filtered_nodes_test[self.drug_inchi_name]))]\n",
    "                    print (\"pred_drugs_dataframe : \", pred_drugs_dataframe.shape)\n",
    "\n",
    "                pred_drug_list = list(pred_drugs_dataframe[self.drug_inchi_name])\n",
    "                pred_normalized_drug_embeddings = np.array(list(pred_drugs_dataframe['normalized_embeddings']))\n",
    "\n",
    "                drug_embed_len = pred_normalized_drug_embeddings[0].shape[0]\n",
    "\n",
    "                X_0_test_ut, X_1_test_ut = self.dataframe_to_embed_array(interactions_df = filtered_nodes_test,\n",
    "                                                                         drug_list = pred_drug_list,\n",
    "                                                                         target_list = pred_target_list,\n",
    "                                                                         drug_embed_len = drug_embed_len,\n",
    "                                                                         normalized_drug_embeddings = pred_normalized_drug_embeddings,\n",
    "                                                                         normalized_target_embeddings = pred_normalized_target_embeddings,\n",
    "                                                                         include_true_label = False)\n",
    "\n",
    "\n",
    "                print (\"X0, X1 : \",  X_0_test_ut.shape, X_1_test_ut.shape)\n",
    "\n",
    "                # Test on unseen nodes\n",
    "                Y_test_predictions_ut = []\n",
    "                Y_test_predictions_ut.extend(model.predict([X_0_test_ut, X_1_test_ut]))\n",
    "                Y_test_predictions_ut = [x[0] if not np.isnan(x[0]) else 0 for x in Y_test_predictions_ut]\n",
    "\n",
    "                pred = Y_test_predictions_ut\n",
    "\n",
    "                prediction_unseen_targets['model_' + str(model_run_number)][sets_run_number] = pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate mean - one dataset, all models\n",
    "        for sets_run_number in range(len(test_sets)):\n",
    "\n",
    "            unseen_targets_pred = []\n",
    "\n",
    "            for model_run_number in range(len(model_paths)):\n",
    "\n",
    "                unseen_targets_pred.append(prediction_unseen_targets['model_' + str(model_run_number)][sets_run_number])\n",
    "            \n",
    "            \n",
    "            unseen_targets_pred = np.mean(np.array(unseen_targets_pred), axis = 0)\n",
    "            print (\"unseen_targets_pred : \", unseen_targets_pred.shape)\n",
    "            print (\"list : \", len(list(unseen_targets_pred)))\n",
    "            \n",
    "            # Update DataFrames\n",
    "            self.fold_test_results[model_name][sets_run_number]['Averaged Predictions'] = list(unseen_targets_pred)\n",
    "\n",
    "        if return_dataframes:\n",
    "            return self.fold_test_results[model_name]\n",
    "\n",
    "    def get_test_results(self, model_name = None, version_number = None, optimal_validation_model = None, drug_filter_list = [], target_filter_list = [], write_plot_to_disk = False, plot_dir = None, plot_name = None):\n",
    "\n",
    "        '''\n",
    "            Computes test results \n",
    "\n",
    "            Inputs : \n",
    "                model_name : String - Key of model used while trainig. If None, class variable will be picked up\n",
    "                optimal_validation_model : Integer - Index of optimal epoch to use \n",
    "                version_number : Integer - Enter version number of the model \n",
    "                drug_filter_list : List - List of InChi keys to filter and test on \n",
    "                target_filter_list : List - List of AA Sequences to filter and test on \n",
    "\n",
    "        '''\n",
    "\n",
    "        # Initialise dictionary\n",
    "        try: \n",
    "            self.test_results\n",
    "        except: \n",
    "            self.test_results = {}\n",
    "\n",
    "        if type(model_name) != type(None) and type(version_number) == type(None):\n",
    "            raise ValueError(\"Please enter a version number for the model\")\n",
    "\n",
    "        if type(model_name) == type(None):\n",
    "                model_name = list(self.results.keys())[0]\n",
    "        else: \n",
    "            model_name = model_name + \"_v\" + str(version_number)\n",
    "\n",
    "        if type(optimal_validation_model) == type(None):    \n",
    "            optimal_validation_model = self.optimal_validation_model[model_name]\n",
    "\n",
    "        if model_name not in self.test_results.keys():\n",
    "            self.test_results[model_name] = {}\n",
    "\n",
    "        for run_number in range(len(self.train_sets)):\n",
    "\n",
    "            model_prefix = \"_\".join(os.listdir(self.model_out_dir[model_name].rstrip('/') + '/Run_' + str(run_number))[0].split('_')[:-4])\n",
    "            model_suffix = self.model_name_index[model_name][optimal_validation_model]\n",
    "            model_location = model_prefix + model_suffix\n",
    "\n",
    "            print (\"Testing on model : \", model_location)\n",
    "\n",
    "            drug_embed_len = self.normalized_drug_embeddings[0].shape[0]\n",
    "\n",
    "            filtered_nodes_test = self.nodes_test[run_number]\n",
    "            filtered_edges_test = self.edges_test[run_number]\n",
    "\n",
    "            if drug_filter_list != [] and target_filter_list != []:\n",
    "                filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.drug_inchi_name].isin(drug_filter_list)) & (filtered_nodes_test[self.target_seq_name].isin(target_filter_list))]\n",
    "                filtered_edges_test = filtered_edges_test[(filtered_edges_test[self.drug_inchi_name].isin(drug_filter_list)) & (filtered_edges_test[self.target_seq_name].isin(target_filter_list))]\n",
    "\n",
    "            elif drug_filter_list != [] and target_filter_list == []:\n",
    "                filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.drug_inchi_name].isin(drug_filter_list))]\n",
    "                filtered_edges_test = filtered_edges_test[(filtered_edges_test[self.drug_inchi_name].isin(drug_filter_list))]\n",
    "\n",
    "            elif drug_filter_list == [] and target_filter_list != []:\n",
    "                filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.target_seq_name].isin(target_filter_list))]\n",
    "                filtered_edges_test = filtered_edges_test[(filtered_edges_test[self.target_seq_name].isin(target_filter_list))]\n",
    "\n",
    "            else: \n",
    "                None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            X_0_test_ut, X_1_test_ut, Y_test_actual_ut = self.dataframe_to_embed_array(interactions_df = filtered_nodes_test,\n",
    "                                                                              drug_list = self.drug_list,\n",
    "                                                                              target_list = self.target_list,\n",
    "                                                                              drug_embed_len = drug_embed_len)\n",
    "\n",
    "            X_0_test_ue, X_1_test_ue, Y_test_actual_ue = self.dataframe_to_embed_array(interactions_df = filtered_edges_test,\n",
    "                                                                                  drug_list = self.drug_list,\n",
    "                                                                                  target_list = self.target_list,\n",
    "                                                                                  drug_embed_len = drug_embed_len)\n",
    "\n",
    "            model = load_model(self.model_out_dir[model_name].rstrip('/') + '/Run_' + str(run_number) + '/' + model_location)\n",
    "\n",
    "            # Test on unseen nodes\n",
    "            Y_test_predictions_ut = []\n",
    "            Y_test_predictions_ut.extend(model.predict([X_0_test_ut, X_1_test_ut]))\n",
    "            Y_test_predictions_ut = [x[0] if not np.isnan(x[0]) else 0 for x in Y_test_predictions_ut]\n",
    "\n",
    "            true = Y_test_actual_ut\n",
    "            pred = Y_test_predictions_ut\n",
    "\n",
    "            f1_scores = []\n",
    "\n",
    "            for j in np.arange(0.0, 1.0, 0.01):\n",
    "                f1_scores.append(f1_score(true, [1 if (i > j) else 0 for i in pred]))\n",
    "\n",
    "            f_1_thresh = [idx for idx, x in list(zip(np.arange(0.0, 1.0, 0.01), f1_scores)) if x == max(f1_scores)][0]\n",
    "\n",
    "            pred_bin = [1 if (i > f_1_thresh) else 0 for i in pred]\n",
    "\n",
    "\n",
    "            try: \n",
    "                self.test_results[model_name][run_number]\n",
    "            except:\n",
    "                self.test_results[model_name][run_number] = {}\n",
    "\n",
    "            self.test_results[model_name][run_number]['unseen_targets_auc'] = roc_auc_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_targets_aup'] = average_precision_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_targets_f1_scores'] = f1_scores\n",
    "            self.test_results[model_name][run_number]['unseen_targets_max_f1'] = np.max(f1_scores)\n",
    "            self.test_results[model_name][run_number]['unseen_targets_f1_threshold'] = f_1_thresh\n",
    "            self.test_results[model_name][run_number]['targets_confusion_matrix'] = confusion_matrix(true, pred_bin)\n",
    "\n",
    "            # Test on unseen edges\n",
    "            Y_test_predictions_ue = []\n",
    "            Y_test_predictions_ue.extend(model.predict([X_0_test_ue, X_1_test_ue]))\n",
    "            Y_test_predictions_ue = [x[0] if not np.isnan(x[0]) else 0 for x in Y_test_predictions_ue]\n",
    "\n",
    "            true = Y_test_actual_ue\n",
    "            pred = Y_test_predictions_ue\n",
    "\n",
    "            f1_scores = []\n",
    "\n",
    "            for j in np.arange(0.0, 1.0, 0.01):\n",
    "                f1_scores.append(f1_score(true, [1 if (i > j) else 0 for i in pred]))\n",
    "\n",
    "            f_1_thresh = [idx for idx, x in list(zip(np.arange(0.0, 1.0, 0.01), f1_scores)) if x == max(f1_scores)][0]\n",
    "\n",
    "            pred_bin = [1 if (i > f_1_thresh) else 0 for i in pred]\n",
    "\n",
    "            self.test_results[model_name][run_number]['unseen_edges_auc'] = roc_auc_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_edges_aup'] = average_precision_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_edges_f1_scores'] = f1_scores\n",
    "            self.test_results[model_name][run_number]['unseen_edges_max_f1'] = np.max(f1_scores)\n",
    "            self.test_results[model_name][run_number]['unseen_edges_f1_threshold'] = f_1_thresh\n",
    "            self.test_results[model_name][run_number]['edges_confusion_matrix'] = confusion_matrix(true, pred_bin)\n",
    "\n",
    "        ue_auc = []\n",
    "        ue_aup = []\n",
    "        ut_auc = []\n",
    "        ut_aup = []\n",
    "        f1_t_e = []\n",
    "        f1_t_t = []\n",
    "        f1_t = []\n",
    "        f1_e = []\n",
    "        all_f1_t = []\n",
    "        all_f1_e = []\n",
    "\n",
    "        conf_t = []\n",
    "        conf_e = []\n",
    "\n",
    "\n",
    "        for run_number in self.test_results[model_name].keys():\n",
    "\n",
    "            # Averaged confusion matrix \n",
    "            conf_tot_t = np.sum(self.test_results[model_name][run_number]['targets_confusion_matrix'], axis = 0)\n",
    "            conf_tot_e = np.sum(self.test_results[model_name][run_number]['edges_confusion_matrix'], axis = 0)\n",
    "\n",
    "            ue_auc.append(self.test_results[model_name][run_number]['unseen_edges_auc'])\n",
    "            ue_aup.append(self.test_results[model_name][run_number]['unseen_edges_aup'])\n",
    "            ut_auc.append(self.test_results[model_name][run_number]['unseen_targets_auc'])\n",
    "            ut_aup.append(self.test_results[model_name][run_number]['unseen_targets_aup'])\n",
    "            f1_t_e.append(self.test_results[model_name][run_number]['unseen_edges_f1_threshold'])\n",
    "            f1_t_t.append(self.test_results[model_name][run_number]['unseen_targets_f1_threshold'])    \n",
    "            f1_t.append(self.test_results[model_name][run_number]['unseen_targets_max_f1'])\n",
    "            f1_e.append(self.test_results[model_name][run_number]['unseen_edges_max_f1'])\n",
    "            all_f1_t.append(self.test_results[model_name][run_number]['unseen_targets_f1_scores'])\n",
    "            all_f1_e.append(self.test_results[model_name][run_number]['unseen_edges_f1_scores'])\n",
    "            if self.test_results[model_name][run_number]['targets_confusion_matrix'][0][0] != 0:\n",
    "                conf_t.append(self.test_results[model_name][run_number]['targets_confusion_matrix'] / conf_tot_t)\n",
    "                conf_e.append(self.test_results[model_name][run_number]['edges_confusion_matrix'] / conf_tot_e)\n",
    "\n",
    "        # Compute mean and error bars for F1 plots\n",
    "        all_f1_t_err = np.std(np.array(all_f1_t), axis = 0)\n",
    "        all_f1_e_err = np.std(np.array(all_f1_e), axis = 0)\n",
    "        all_f1_t = np.mean(np.array(all_f1_t), axis = 0)\n",
    "        all_f1_e = np.mean(np.array(all_f1_e), axis = 0)\n",
    "\n",
    "        # Compute mean and deviation for the confusion matrix \n",
    "        target_conf = np.zeros((2, 2), dtype = object)\n",
    "        t_conf_mean = np.mean(conf_t, axis = 0)\n",
    "        t_conf_err = np.std(conf_t, axis = 0)\n",
    "\n",
    "    \n",
    "        if len(conf_t) != 0:\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    target_conf[i][j] = str(np.round(t_conf_mean[i][j], 2)) + \" +/- \" + str(np.round(t_conf_err[i][j], 2))\n",
    "        target_conf = pd.DataFrame(target_conf) \n",
    "\n",
    "        results_df = pd.DataFrame(np.zeros((4, 2), dtype = object))\n",
    "        results_df.index = ['AUC', 'AUP', 'F1 Score', 'F1 Threshold']\n",
    "        results_df.columns = ['Unseen Nodes / Targets', 'Unseen Edges']\n",
    "\n",
    "        results_df.iloc[0, 0] = str(np.round(np.mean(ut_auc), 3)) + \" +/- \" + str(np.round(np.std(ut_auc), 3))\n",
    "        results_df.iloc[1, 0] = str(np.round(np.mean(ut_aup), 3)) + \" +/- \" + str(np.round(np.std(ut_aup), 3))\n",
    "        results_df.iloc[2, 0] = str(np.round(np.mean(f1_t), 3)) + \" +/- \" + str(np.round(np.std(f1_t), 3))\n",
    "        results_df.iloc[3, 0] = str(np.round(np.mean(f1_t_t), 3)) + \" +/- \" + str(np.round(np.std(f1_t_t), 3))\n",
    "        results_df.iloc[0, 1] = str(np.round(np.mean(ue_auc), 3)) + \" +/- \" + str(np.round(np.std(ue_auc), 3))\n",
    "        results_df.iloc[1, 1] = str(np.round(np.mean(ue_aup), 3)) + \" +/- \" + str(np.round(np.std(ue_aup), 3))\n",
    "        results_df.iloc[2, 1] = str(np.round(np.mean(f1_e), 3)) + \" +/- \" + str(np.round(np.std(f1_e), 3))\n",
    "        results_df.iloc[3, 1] = str(np.round(np.mean(f1_t_e), 3)) + \" +/- \" + str(np.round(np.std(f1_t_e), 3))\n",
    "\n",
    "        display (results_df)\n",
    "\n",
    "        print (\"Confusion Matrix - Unseen Nodes / Targets : \")\n",
    "        target_conf.columns = ['Pred (0)', 'Pred (1)']\n",
    "        target_conf.index = ['True (0)', 'True (1)']\n",
    "        display(target_conf)\n",
    "\n",
    "        # Compute mean and deviation for the confusion matrix \n",
    "        edge_conf = np.zeros((2, 2), dtype = object)\n",
    "        e_conf_mean = np.mean(conf_e, axis = 0)\n",
    "        e_conf_err = np.std(conf_e, axis = 0)\n",
    "\n",
    "        if len(conf_e) != 0:\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    edge_conf[i][j] = str(np.round(e_conf_mean[i][j], 2)) + \" +/- \" + str(np.round(e_conf_err[i][j], 2))\n",
    "        edge_conf = pd.DataFrame(edge_conf) \n",
    "\n",
    "        print (\"Confusion Matrix - Unseen Edges : \")\n",
    "        edge_conf.columns = ['Pred (0)', 'Pred (1)']\n",
    "        edge_conf.index = ['True (0)', 'True (1)']\n",
    "        display(edge_conf)\n",
    "\n",
    "        \n",
    "        plt.errorbar(np.arange(0.0, 1.0, 0.01), all_f1_t, all_f1_t_err)\n",
    "        plt.xlabel('Thresholds')\n",
    "        plt.ylabel('F1 Scores')\n",
    "        plt.title('F1 Scores For Unseen Nodes/Targets')\n",
    "        plt.show()\n",
    "\n",
    "        if write_plot_to_disk:\n",
    "            plt.savefig(plot_dir.rstrip('/') + plot_name + \"_nodes.png\")\n",
    "\n",
    "        plt.errorbar(np.arange(0.0, 1.0, 0.01), all_f1_e, all_f1_e_err)\n",
    "        plt.xlabel('Thresholds')\n",
    "        plt.ylabel('F1 Scores')\n",
    "        plt.title('F1 Scores For Unseen Edges')\n",
    "        plt.show()\n",
    "\n",
    "        if write_plot_to_disk:\n",
    "            plt.savefig(plot_dir.rstrip('/') + plot_name + \"_edges.png\")\n",
    "\n",
    "    ###################################################\n",
    "    ############ VecNet Specific Functions ############\n",
    "    ###################################################\n",
    "\n",
    "    # Get Drug Embeddings From Mol2Vec\n",
    "    def get_mol2vec_embeddings(self, prediction_interactions = None, embedding_dimension = 300, replace_dataframe = True, return_normalisation_conststants = False):\n",
    "\n",
    "        '''\n",
    "        Generate Mol2Vec embeddings for all drugs in the drugs dataframe \n",
    "\n",
    "        Inputs : \n",
    "            embedding_dimension : Integer - Number of dimensions the Mol2Vec model expects\n",
    "            prediction_interactions : Pandas DataFrame - Dataframe with prediction information\n",
    "            replace_dataframe : Bool - Replace existing drugs dataframe with one that contains InChi Key and its respective normalised Mol2Vec embedding\n",
    "            return_normalisation_conststants : Bool - Returns normalisation constant if true\n",
    "\n",
    "        Outputs (optional): \n",
    "            centered_drug_embeddings : Numpy Array\n",
    "            centered_drug_embeddings_length : Float\n",
    "            normalized_drug_embeddings : Numpy Array\n",
    "        '''\n",
    "\n",
    "        # Create dictionary to hold drug_inchi : drug_smile\n",
    "        drug_smiles = {}\n",
    "\n",
    "        if type(prediction_interactions) != type(None):\n",
    "            drugs_dataframe = prediction_interactions[[self.drug_inchi_name, self.drug_smile_name]]\n",
    "            replace_dataframe = False\n",
    "        else: \n",
    "            drugs_dataframe = self.drugs_dataframe\n",
    "\n",
    "\n",
    "        for index, row in tqdm(drugs_dataframe.iterrows()):\n",
    "\n",
    "            drug_id = row[self.drug_inchi_name]\n",
    "            drug_smile = row[self.drug_smile_name]\n",
    "\n",
    "            drug_smiles[drug_id] = drug_smile\n",
    "\n",
    "        # Read in Mol2Vec model\n",
    "        if type(self.mol2vec_model) == type(None):\n",
    "            self.mol2vec_model = word2vec.Word2Vec.load(self.mol2vec_location)\n",
    "\n",
    "        # Create empty array to hold embeddings\n",
    "        drug_embeddings = np.zeros((len(drug_smiles.keys()), embedding_dimension))\n",
    "        miss_words = []\n",
    "        hit_words = 0\n",
    "        bad_mol = 0\n",
    "        percent_unknown = []\n",
    "\n",
    "        # Iterate over all drugs in dataset\n",
    "        for idx, drug in tqdm(enumerate(drug_smiles.keys())):\n",
    "            flag = 0\n",
    "            mol_miss_words = 0\n",
    "\n",
    "            # Create molecule object from smiles\n",
    "            molecule = Chem.MolFromSmiles(drug_smiles[drug])\n",
    "            try:\n",
    "                # Get fingerprint from molecule\n",
    "                sub_structures = mol2alt_sentence(molecule, 2)\n",
    "            except Exception as e: \n",
    "                if self.debug: \n",
    "                    print (e)\n",
    "                percent_unknown.append(100)\n",
    "                continue    \n",
    "\n",
    "            # Iterate over each sub structure\n",
    "            for sub in sub_structures:\n",
    "                # Check to see if substructure exists\n",
    "                try:\n",
    "                    drug_embeddings[idx, :] = drug_embeddings[idx, :] + self.mol2vec_model.wv[sub]\n",
    "                    hit_words = hit_words + 1\n",
    "\n",
    "                # If not, replace with UNK (unknown)\n",
    "                except Exception as e:\n",
    "                    if self.debug : \n",
    "                        print (\"Sub structure not found\")\n",
    "                        print (e)\n",
    "                    drug_embeddings[idx, :] = drug_embeddings[idx, :] + self.mol2vec_model.wv['UNK']\n",
    "                    miss_words.append(sub)\n",
    "                    flag = 1\n",
    "                    mol_miss_words = mol_miss_words + 1\n",
    "\n",
    "            percent_unknown.append((mol_miss_words / len(sub_structures)) * 100)\n",
    "\n",
    "            if flag == 1:\n",
    "                bad_mol = bad_mol + 1 \n",
    "\n",
    "        # Normalise embeddings\n",
    "        if type(prediction_interactions) == type(None):\n",
    "            self.mean_drug_embeddings = np.mean(drug_embeddings, axis = 0)\n",
    "            self.centered_drug_embeddings = drug_embeddings - self.mean_drug_embeddings\n",
    "            self.centered_drug_embeddings_length = np.mean(np.sqrt(np.sum(self.centered_drug_embeddings * self.centered_drug_embeddings, axis = 1)))\n",
    "            self.normalized_drug_embeddings = self.centered_drug_embeddings / np.expand_dims(self.centered_drug_embeddings_length, axis = -1)\n",
    "        \n",
    "        # If prediction data, use previous info to normalise and return \n",
    "        else: \n",
    "            centered_drug_embeddings = drug_embeddings - self.mean_drug_embeddings\n",
    "            normalized_drug_embeddings = centered_drug_embeddings / np.expand_dims(self.centered_drug_embeddings_length, axis = -1)\n",
    "            drugs_dataframe = pd.DataFrame([list(drug_smiles.keys()), normalized_drug_embeddings]).T\n",
    "            drugs_dataframe.columns = [self.drug_inchi_name, 'normalized_embeddings']\n",
    "            return drugs_dataframe\n",
    "\n",
    "        # Replace drugs dataframe with one with two columns - InChi Key and 'normalized_embeddings'\n",
    "        if replace_dataframe: \n",
    "            self.drugs_dataframe = pd.DataFrame([list(drug_smiles.keys()), self.normalized_drug_embeddings]).T\n",
    "            self.drugs_dataframe.columns = [self.drug_inchi_name, 'normalized_embeddings']\n",
    "            self.drug_list = list(self.drugs_dataframe[self.drug_inchi_name])\n",
    "\n",
    "        # Return normalized constants and values to save\n",
    "        if return_normalisation_conststants: \n",
    "            return self.centered_drug_embeddings, self.centered_drug_embeddings_length, self.normalized_drug_embeddings\n",
    "\n",
    "    # Get Target Embeddings From ProtVec\n",
    "    def get_protvec_embeddings(self, prediction_interactions = None, embedding_dimension = 100, replace_dataframe = True, return_normalisation_conststants = False, delimiter = '\\t'):\n",
    "\n",
    "        '''\n",
    "            Reads in ProtVec model generates embeddings for all targets in targets dataframe \n",
    "\n",
    "            Inputs : \n",
    "            embedding_dimension : Integer - Dimensions of ProtVec embedding\n",
    "            prediction_interactions : Pandas DataFrame - Dataframe with prediction information\n",
    "            replace_dataframe : Bool - Replace existing targets dataframe with one that contains AA Sequences and its respective normalised ProtVec embedding\n",
    "            return_normalisation_conststants : Bool - Returns normalisation constant if true\n",
    "            delimiter : String - Delimiter for reading in Pandas ProtVec DataFrame\n",
    "        '''\n",
    "\n",
    "        if type(prediction_interactions) != type(None):\n",
    "            target_list = list(prediction_interactions[self.target_seq_name])\n",
    "            replace_dataframe = False\n",
    "        else: \n",
    "            target_list = self.target_list\n",
    "\n",
    "        # Read in ProtVec model\n",
    "        if type(self.protvec_model) == type(None): \n",
    "            self.protvec_model = pd.read_csv(self.protvec_location, delimiter = delimiter)\n",
    "\n",
    "        # Create dictionary of words : values for faster indexing\n",
    "        trigram_dict = {}\n",
    "        for idx, row in tqdm(self.protvec_model.iterrows()):\n",
    "\n",
    "            trigram_dict[row['words']] = self.protvec_model.iloc[idx, 1:].values.astype(np.float)\n",
    "\n",
    "        trigram_list = set(trigram_dict.keys())\n",
    "\n",
    "        target_embeddings = np.zeros((len(target_list), embedding_dimension))\n",
    "        length_of_target = [0 for _ in range(len(target_list))]\n",
    "\n",
    "        # For each target in target list\n",
    "        for idx, target in tqdm(enumerate(target_list)):\n",
    "\n",
    "            n = 3\n",
    "            split_by_three = [target[i : i + n] for i in range(0, len(target), n)]\n",
    "            length_of_target[idx] = len(split_by_three)\n",
    "\n",
    "            for trigram in split_by_three: \n",
    "\n",
    "                if len(trigram) == 2: \n",
    "                    trigram = \"X\" + trigram\n",
    "\n",
    "                elif len(trigram) == 1:\n",
    "                    trigram = \"XX\" + trigram\n",
    "\n",
    "                if trigram in trigram_list:\n",
    "                    target_embeddings[idx, :] = target_embeddings[idx, :] + trigram_dict[trigram]\n",
    "\n",
    "        # Normalize embeddings - train data\n",
    "        if type(prediction_interactions) == type(None):\n",
    "            self.target_embeddings = target_embeddings\n",
    "            self.mean_target_embeddings = np.mean(target_embeddings, axis = 0)\n",
    "            self.centered_target_embeddings = target_embeddings - self.mean_target_embeddings\n",
    "            self.centered_target_embeddings_length = np.mean(np.sqrt(np.sum(self.centered_target_embeddings * self.centered_target_embeddings, axis = 1)))\n",
    "            self.normalized_target_embeddings = self.centered_target_embeddings / np.expand_dims(self.centered_target_embeddings_length, axis = -1)\n",
    "\n",
    "        # Normalize for prediction data and return \n",
    "        else: \n",
    "            centered_target_embeddings = target_embeddings - self.mean_target_embeddings\n",
    "            normalized_target_embeddings = centered_target_embeddings / np.expand_dims(self.centered_target_embeddings_length, axis = -1)\n",
    "            targets_dataframe = pd.DataFrame([target_list, normalized_target_embeddings]).T\n",
    "            targets_dataframe.columns = [self.target_seq_name, 'normalized_embeddings']\n",
    "            return targets_dataframe\n",
    "\n",
    "        # Replace targets dataframe with \n",
    "        if replace_dataframe: \n",
    "            self.targets_dataframe = pd.DataFrame([target_list, self.normalized_target_embeddings]).T\n",
    "            self.targets_dataframe.columns = [self.target_seq_name, 'normalized_embeddings']\n",
    "\n",
    "        if return_normalisation_conststants:\n",
    "            return self.target_embeddings, self.centered_target_embeddings_length, self.normalized_target_embeddings\n",
    "\n",
    "    def vecnet_2048_2048_concat_512_512(self):\n",
    "\n",
    "        '''\n",
    "            Model definition for VecNet\n",
    "        '''\n",
    "\n",
    "        target_input = Input(shape = (100,))\n",
    "        X_0 = Dense(2048, kernel_initializer = glorot_uniform(), activation = 'relu')(target_input)\n",
    "\n",
    "        drugs_input = Input(shape = (300,))\n",
    "        X_1 = Dense(2048, kernel_initializer = glorot_uniform(), activation = 'relu')(drugs_input)\n",
    "\n",
    "        combined = Concatenate(axis = -1)([X_0, X_1])\n",
    "        X = Dropout(0.5)(combined)\n",
    "\n",
    "        X = Dense(512, kernel_initializer = glorot_uniform())(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = Dense(512, kernel_initializer = glorot_uniform())(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = Dense(1, kernel_initializer = glorot_uniform())(X)\n",
    "        X = Activation('sigmoid')(X)\n",
    "\n",
    "        model = Model(inputs = [target_input, drugs_input] , outputs = X)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train_vecnet(self, model_name, epochs, version = None, learning_rate = 0.00001, beta_1 = 0.9, beta_2 = 0.999, batch_size = 16, chunk_split_size = 500, chunk_test_frequency = 250, interactive = True):\n",
    "\n",
    "        '''\n",
    "            Trains VecNet and saves models to disk \n",
    "\n",
    "            model_name : String - Key to save model \n",
    "            epochs : Integer - Number of epochs to train \n",
    "            version : Integer - Version number to use while saving model \n",
    "            learning_rate : Float - Learning rate to use during optimisation\n",
    "            beta_1 : Float - Beta parameters for Adam optimisation \n",
    "            beta_2 : Float - Beta parameters for Adam optimisation\n",
    "            batch_size : Integer - Batch size for training\n",
    "            chunk_split_size : Integer - Size to split training interactions into \n",
    "            chunk_test_frequency : Integer - Number of chunks after which validation is performed and model saved \n",
    "        '''\n",
    "\n",
    "        self.normalized_target_embeddings = np.array(list(self.targets_dataframe['normalized_embeddings']))\n",
    "        self.normalized_drug_embeddings = np.array(list(self.drugs_dataframe['normalized_embeddings']))\n",
    "\n",
    "        # Check if variable exists\n",
    "        try:\n",
    "            self.results\n",
    "        except:\n",
    "            self.results = {}\n",
    "        try:\n",
    "            self.model_name_index\n",
    "        except:\n",
    "            self.model_name_index = {}\n",
    "\n",
    "        if type(model_name) != type(None) and model_name in self.results.keys():\n",
    "            if interactive :\n",
    "                print (\"The same model name and version number exist. Please pick new values \")\n",
    "                model_name = input(\"Model Name : \")\n",
    "                version = input(\"Version : \")\n",
    "            else: \n",
    "                print (\"Model name already exists - adding random version to model name\")\n",
    "                version = str(np.random.randint(0, 100))\n",
    "                print (\"Updated verison number : \", version)\n",
    "\n",
    "        if type(version) == type(None):\n",
    "\n",
    "            if interactive:\n",
    "                version = input(\"Version : \")\n",
    "            else: \n",
    "                version = np.random.randint(0, 100)\n",
    "\n",
    "        model_name = model_name + '_v' + str(version)\n",
    "        if type(self.model_out_dir) != type({}):\n",
    "            \n",
    "            current_dir = self.model_out_dir\n",
    "            self.model_out_dir = {}\n",
    "            self.model_out_dir[model_name] = current_dir\n",
    "\n",
    "        if np.sum([1 if 'Run_' in content else 0 for content in os.listdir(self.model_out_dir[model_name])]) > 0:\n",
    "\n",
    "            if interactive:\n",
    "                print (\"There already exists saved model data in this directory. Please select a new directory for this training or train as part of a new AIBind object.\")\n",
    "                self.model_out_dir[model_name] = input('New directory : ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        version = str(version)\n",
    "        v_num = version\n",
    "\n",
    "        # Iterate over k folds\n",
    "        for run_number in tqdm(range(len(self.train_sets))):\n",
    "\n",
    "            # Set class weights to reflect train set positive to negative ratio\n",
    "            class_weight = {0: self.train_pos_neg_ratio[run_number],\n",
    "                            1: 1}\n",
    "\n",
    "            # Create Lists To Hold Information\n",
    "            val_auc_ut = []\n",
    "            val_auc_ue = []\n",
    "            val_aup_ut = []\n",
    "            val_aup_ue = []\n",
    "\n",
    "            loss = []\n",
    "            acc = []\n",
    "\n",
    "            # Reinitialise Model At Each Run \n",
    "            model = self.vecnet_2048_2048_concat_512_512()\n",
    "            model_optimizer = tensorflow.keras.optimizers.Adam(lr = learning_rate, beta_1 = beta_1, beta_2 = beta_2, amsgrad = False)\n",
    "            model.compile(loss = 'binary_crossentropy', optimizer = model_optimizer, metrics = ['binary_accuracy'])\n",
    "\n",
    "            # Create TQDM Object So We Can Play With Printed String\n",
    "            t = tqdm(np.random.choice(range(epochs), epochs, replace = False))\n",
    "\n",
    "            # Create File Name To Save Model\n",
    "            version = v_num + \"_run\" + str(run_number) + \"_\" + pd.to_datetime(time.time(), unit = 's').strftime('%m-%d_%Hh%M')\n",
    "\n",
    "            # Create Validation DataFrames For Each Run\n",
    "            drug_embed_len = self.normalized_drug_embeddings[0].shape[0]\n",
    "\n",
    "            X_0_val_ut, X_1_val_ut, Y_val_actual_ut = self.dataframe_to_embed_array(interactions_df = self.nodes_validation[run_number],\n",
    "                                                                                  drug_list = self.drug_list,\n",
    "                                                                                  target_list = self.target_list,\n",
    "                                                                                  drug_embed_len = drug_embed_len)\n",
    "\n",
    "            X_0_val_ue, X_1_val_ue, Y_val_actual_ue = self.dataframe_to_embed_array(interactions_df = self.edges_validation[run_number],\n",
    "                                                                                  drug_list = self.drug_list,\n",
    "                                                                                  target_list = self.target_list,\n",
    "                                                                                  drug_embed_len = drug_embed_len)\n",
    "\n",
    "            # Create Variable For Seen Targets Needed Later\n",
    "            seen_targets = list(self.train_sets[run_number][self.target_seq_name])\n",
    "\n",
    "            # Counter to keep track of model names during testing\n",
    "            model_index_counter = 0\n",
    "\n",
    "            model_key = model_name\n",
    "            if model_key not in self.model_name_index.keys():\n",
    "                self.model_name_index[model_key] = {}\n",
    "\n",
    "\n",
    "            # For Each Epoch\n",
    "            for ep, i in enumerate(t):\n",
    "\n",
    "\n",
    "                # Slice Into Chunks\n",
    "                interactions_sliced = np.array_split(self.train_sets[run_number], len(self.train_sets[run_number]) / chunk_split_size)\n",
    "\n",
    "                # Train On Each Chunk\n",
    "                for idx, interaction in enumerate(interactions_sliced):\n",
    "\n",
    "                    output_string = \"\"\n",
    "\n",
    "                    X_0, X_1, Y = self.dataframe_to_embed_array(interactions_df = interaction,\n",
    "                                                           drug_list = self.drug_list, \n",
    "                                                           target_list = self.target_list,\n",
    "                                                           drug_embed_len = drug_embed_len)\n",
    "\n",
    "                    history = model.fit([X_0, X_1], Y,\n",
    "                                          batch_size = batch_size,\n",
    "                                          epochs = 1,\n",
    "                                          class_weight = class_weight,\n",
    "                                          verbose = 0)\n",
    "\n",
    "                    if idx % chunk_test_frequency == 0:\n",
    "\n",
    "                        # Calculate and Save Unseen Target Performance\n",
    "                        Y_val_predictions_ut = []\n",
    "                        Y_val_predictions_ut.extend(model.predict([X_0_val_ut, X_1_val_ut]))\n",
    "                        Y_val_predictions_ut = [x[0] for x in Y_val_predictions_ut]\n",
    "                        curr_val_auc = roc_auc_score(Y_val_actual_ut, Y_val_predictions_ut)\n",
    "                        curr_val_aup = average_precision_score(Y_val_actual_ut, Y_val_predictions_ut)\n",
    "                        val_auc_ut.append(curr_val_auc)\n",
    "                        val_aup_ut.append(curr_val_aup)\n",
    "\n",
    "                        Y_val_predictions_ue = []\n",
    "                        Y_val_predictions_ue.extend(model.predict([X_0_val_ue, X_1_val_ue]))\n",
    "                        Y_val_predictions_ue = [x[0] for x in Y_val_predictions_ue]\n",
    "                        curr_val_auc = roc_auc_score(Y_val_actual_ue, Y_val_predictions_ue)\n",
    "                        curr_val_aup = average_precision_score(Y_val_actual_ue, Y_val_predictions_ue)\n",
    "                        val_aup_ue.append(curr_val_aup)\n",
    "                        val_auc_ue.append(curr_val_auc)\n",
    "\n",
    "                        # Print Stuff\n",
    "                        output_string = output_string + \"Unseen Nodes AUC : \" + str(np.round(val_auc_ut[-1], 2)) + \"\\nUnseen Edges AUC : \" +  str(np.round(val_auc_ue[-1], 2)) + \"\\n\"\n",
    "                        output_string = output_string + \"Unseen Nodes AUP : \" + str(np.round(val_aup_ut[-1], 2)) + \"\\nUnseen Edges AUP : \" +  str(np.round(val_aup_ue[-1], 2)) + \"\\n\"\n",
    "\n",
    "                        # Save Model\n",
    "                        if not os.path.isdir(self.model_out_dir[model_name].rstrip('/') + '/Run_' + str(run_number)):\n",
    "                            os.mkdir(self.model_out_dir[model_name].rstrip('/') + '/Run_' + str(run_number))\n",
    "                        model.save(self.model_out_dir[model_name].rstrip('/') + '/Run_' + str(run_number) + '/' + model_name + str(version) + \"_epoch_\" + str(ep) + \"_idx_\" + str(idx) + '.model')\n",
    "\n",
    "                        self.model_name_index[model_key][model_index_counter] = \"_epoch_\" + str(ep) + \"_idx_\" + str(idx) + '.model'\n",
    "                        model_index_counter = model_index_counter + 1\n",
    "\n",
    "                        t.write(output_string)\n",
    "\n",
    "                        loss = loss + history.history['loss']\n",
    "                        acc = acc + history.history['binary_accuracy']\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                self.results[model_key]\n",
    "            except: \n",
    "                self.results[model_key] = {}\n",
    "\n",
    "            self.results[model_key][run_number] = {}\n",
    "            self.results[model_key][run_number]['val_auc_ut'] = val_auc_ut\n",
    "            self.results[model_key][run_number]['val_auc_ue'] = val_auc_ue\n",
    "            self.results[model_key][run_number]['val_aup_ut'] = val_aup_ut\n",
    "            self.results[model_key][run_number]['val_aup_ue'] = val_aup_ue\n",
    "            self.results[model_key][run_number]['loss'] = loss\n",
    "            self.results[model_key][run_number]['acc'] = acc  \n",
    "\n",
    "            with open(self.model_out_dir[model_name].rstrip('/') + '/results_' + model_key + '_' + str(v_num) + '.json', 'w') as file: \n",
    "                json.dump(self.results, file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prediction On Unseen Targets Over Drugs and Natural Ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('VecNet_unseen_targets.pickle', 'rb') as file:\n",
    "    vecnet_object = pkl.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interactions = pd.read_csv('/data/sars-busters-consolidated/interactions/dataset_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Expected to have PDB IDs, gene names, and amin acid sequences in 'ID', 'gene', and 'Sequence' columns respectively \n",
    "\n",
    "targets_df = pd.read_csv('csv_file_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899c7a5ee77d4c86bc8a7e1c2736a79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_ligands = set(interactions['InChiKey'].tolist())\n",
    "\n",
    "InChiKey_list = []\n",
    "target_aa_code_list = []\n",
    "ID_list = []\n",
    "gene_list = []\n",
    "\n",
    "for lig in tqdm(unique_ligands):\n",
    "    for index, row in targets_df.iterrows():\n",
    "        InChiKey_list.append(lig)\n",
    "        target_aa_code_list.append(row['Sequence'])\n",
    "        ID_list.append(row['ID'])\n",
    "        gene_list.append(row['gene'])\n",
    "        \n",
    "target_preidcitons = pd.DataFrame()\n",
    "\n",
    "target_preidcitons['InChiKey'] = InChiKey_list\n",
    "target_preidcitons['target_aa_code'] = target_aa_code_list\n",
    "target_preidcitons['ID'] = ID_list\n",
    "target_preidcitons['gene'] = gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on model :  /data/sars-busters-consolidated/GitData/VecNet_Unseen_Nodes/Run_0/vecnet_ds2_5_fold_unseen_nodes_v00_run0_06-16_21h21_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (267663, 4)\n",
      "Drugs :  8111\n",
      "Targets :  33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3bdf754c1445239a0ecf072083fa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddaaa7111c4049edbeb4f51a18b9d7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_drugs_dataframe :  (8096, 2)\n",
      "X0, X1 :  (267663, 100) (267663, 300)\n",
      "Testing on model :  /data/sars-busters-consolidated/GitData/VecNet_Unseen_Nodes/Run_1/vecnet_ds2_5_fold_unseen_nodes_v00_run1_06-16_21h24_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (267663, 4)\n",
      "Drugs :  8111\n",
      "Targets :  33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d12db086a37424ab52b8eacf65340ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ead970437bc43c296979497b503a965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_drugs_dataframe :  (8096, 2)\n",
      "X0, X1 :  (267663, 100) (267663, 300)\n",
      "Testing on model :  /data/sars-busters-consolidated/GitData/VecNet_Unseen_Nodes/Run_2/vecnet_ds2_5_fold_unseen_nodes_v00_run2_06-16_21h29_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (267663, 4)\n",
      "Drugs :  8111\n",
      "Targets :  33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cfacde5fad4be58cbf0a0aec8b67f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3121eade334e76808aa0cd8e7e1fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_drugs_dataframe :  (8096, 2)\n",
      "X0, X1 :  (267663, 100) (267663, 300)\n",
      "Testing on model :  /data/sars-busters-consolidated/GitData/VecNet_Unseen_Nodes/Run_3/vecnet_ds2_5_fold_unseen_nodes_v00_run3_06-16_21h32_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (267663, 4)\n",
      "Drugs :  8111\n",
      "Targets :  33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802854b6f7014a649cdcb90a29fbb13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d21d7b50184c8aa8bf949f77c0d076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_drugs_dataframe :  (8096, 2)\n",
      "X0, X1 :  (267663, 100) (267663, 300)\n",
      "Testing on model :  /data/sars-busters-consolidated/GitData/VecNet_Unseen_Nodes/Run_4/vecnet_ds2_5_fold_unseen_nodes_v00_run4_06-16_21h35_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (267663, 4)\n",
      "Drugs :  8111\n",
      "Targets :  33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a839ceaa42bb47a18a43029c177dd53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a170eefa6d44c0b8e984833df4a070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_drugs_dataframe :  (8096, 2)\n",
      "X0, X1 :  (267663, 100) (267663, 300)\n",
      "unseen_targets_pred :  (267663,)\n",
      "list :  267663\n"
     ]
    }
   ],
   "source": [
    "target_preidcitons_5fold_average = vecnet_object.get_fold_averaged_prediction_results( model_name = None,\n",
    "                                                                                     version_number = None,\n",
    "                                                                                     model_paths = [],\n",
    "                                                                                     optimal_validation_model = None,\n",
    "                                                                                     test_sets = [target_preidcitons],\n",
    "                                                                                     get_drug_embed = False,\n",
    "                                                                                     get_target_embed = True,\n",
    "                                                                                     drug_filter_list = [],\n",
    "                                                                                     target_filter_list = [],\n",
    "                                                                                     return_dataframes = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of ligands:  8111\n",
      "Ligands present in prediction:  8111\n"
     ]
    }
   ],
   "source": [
    "print('Expected number of ligands: ',len(set(target_preidcitons['InChiKey'].tolist())))\n",
    "print('Ligands present in prediction: ',len(set(target_preidcitons[0]['InChiKey'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of pairs:  267663\n",
      "Pairs present in prediction:  267663\n"
     ]
    }
   ],
   "source": [
    "print('Expected number of pairs: ',len(target_preidcitons))\n",
    "print('Pairs present in prediction: ',len(target_preidcitons_5fold_average[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'VecNet Predictions for SARS-CoV-2 genes')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(20, 10), dpi=80)\n",
    "plt.hist(target_preidcitons_5fold_average[0]['Averaged Predictions'].tolist(),density=True,alpha=0.2,bins=20)\n",
    "plt.xlabel('Averaged Prediction')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('VecNet Predictions for Unseen Targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_preidcitons_5fold_average[0].to_csv('dump_file_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prediction on Unseen Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('VecNet_unseen_nodes.pickle', 'rb') as file:\n",
    "    vecnet_object = pkl.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Expected to have 'InChiKey', 'SMILE', and 'target_aa_code'\n",
    "\n",
    "nodes_df = pd.read_csv('csv_file_path')\n",
    "\n",
    "# Example entries\n",
    "#nodes_df['InChiKey'] = ['HUMNYLRZRPPJDN-UHFFFAOYSA-N']\n",
    "#nodes_df['SMILE'] = ['C1=CC=C(C=C1)C=O']\n",
    "#nodes_df['target_aa_code'] = sars_targets['Sequence'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on model :  ./VecNet_Unseen_Nodes/Run_0/vecnet_ds2_5_fold_unseen_nodes_v00_run0_06-15_04h42_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (1, 3)\n",
      "Drugs :  1\n",
      "Targets :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff41b1fa78be4d9ba5266ee56e531f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d785fceabd14ad4b1c4e4edd58b03cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68ebfa0b6104b8aa866158f7e60b370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d91c73b711b407ca45761dc0b8b4fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0, X1 :  (1, 100) (1, 300)\n",
      "Testing on model :  ./VecNet_Unseen_Nodes/Run_1/vecnet_ds2_5_fold_unseen_nodes_v00_run1_06-15_04h46_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (1, 3)\n",
      "Drugs :  1\n",
      "Targets :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f48a60afee460bb3d0c16070476e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60774577a19c401596cdab19ebadce95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6e0bc6d9d54fe3ba1999ebb28f08f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d4ecabbb344dbbbc96008db0b884be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0, X1 :  (1, 100) (1, 300)\n",
      "Testing on model :  ./VecNet_Unseen_Nodes/Run_2/vecnet_ds2_5_fold_unseen_nodes_v00_run2_06-15_04h50_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (1, 3)\n",
      "Drugs :  1\n",
      "Targets :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0974a3476cd4a53b3ea39daa34b1ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9276e903ea4056b90637be001b1519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679e32f93b334b2596d4c5103112c56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dbc9dc2e734dbf9daf6fcb2e8ebf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0, X1 :  (1, 100) (1, 300)\n",
      "Testing on model :  ./VecNet_Unseen_Nodes/Run_3/vecnet_ds2_5_fold_unseen_nodes_v00_run3_06-15_04h54_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (1, 3)\n",
      "Drugs :  1\n",
      "Targets :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e41f1fee58548ed83bad6adef2faaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3974f5a98b478b9f20eb9f70788cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393ae269260d4ed995271eb08c366395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a82c80f55a4b7eb626976ddd1d390e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0, X1 :  (1, 100) (1, 300)\n",
      "Testing on model :  ./VecNet_Unseen_Nodes/Run_4/vecnet_ds2_5_fold_unseen_nodes_v00_run4_06-15_04h56_epoch_19_idx_0.model\n",
      "filtered_nodes_test :  (1, 3)\n",
      "Drugs :  1\n",
      "Targets :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d592a9210848ebb95121f4039ff147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cdcf48a012443d91f6763e0e99fcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a55142889f4f20a75525e528bc2d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b67341b70ed4b7ea32f29db77b33a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0, X1 :  (1, 100) (1, 300)\n",
      "unseen_targets_pred :  (1,)\n",
      "list :  1\n"
     ]
    }
   ],
   "source": [
    "unseen_nodes_example_5fold_average = vecnet_object.get_fold_averaged_prediction_results( model_name = None,\n",
    "                                                                                     version_number = None,\n",
    "                                                                                     model_paths = [],\n",
    "                                                                                     optimal_validation_model = None,\n",
    "                                                                                     test_sets = [nodes_df],\n",
    "                                                                                     get_drug_embed = True,\n",
    "                                                                                     get_target_embed = True,\n",
    "                                                                                     drug_filter_list = [],\n",
    "                                                                                     target_filter_list = [],\n",
    "                                                                                     return_dataframes = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unseen_nodes_example_5fold_average[0].to_csv('dump_file_csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
