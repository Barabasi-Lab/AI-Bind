{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/miniconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda/lib/python3.6/site-packages/rdkit/Chem/PandasTools.py\", line 130, in <module>\n",
      "    if 'display.width' in pd.core.config._registered_options:\n",
      "AttributeError: module 'pandas.core' has no attribute 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import json\n",
    "import lxml\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import plotly.graph_objects as go\n",
    "import umap.umap_ as umap\n",
    "import tensorflow.keras\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from pandarallel import pandarallel\n",
    "from ast import literal_eval\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import Counter\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import FastText\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "\n",
    "from mol2vec import features\n",
    "from mol2vec import helpers\n",
    "from mol2vec.features import mol2alt_sentence, MolSentence, DfVec, sentences2vec\n",
    "from mol2vec.helpers import depict_identifier, plot_2D_vectors, IdentifierTable, mol_to_svg\n",
    "\n",
    "from Bio import SeqUtils\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Conv1D, Flatten, MaxPooling1D,\\\n",
    "                        AveragePooling1D, Concatenate, LeakyReLU, Embedding,\\\n",
    "                        GlobalMaxPooling1D,GlobalAveragePooling1D,GaussianNoise,BatchNormalization,Add\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "pandarallel.initialize(progress_bar = True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GPU Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'Tue Jun  1 16:20:38 2021       \",\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " '| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |',\n",
       " '|-------------------------------+----------------------+----------------------+',\n",
       " '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |',\n",
       " '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |',\n",
       " '|===============================+======================+======================|',\n",
       " '|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |',\n",
       " '| N/A   66C    P0    30W /  70W |  14688MiB / 15079MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |',\n",
       " '| N/A   77C    P0    35W /  70W |   1717MiB / 15079MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '|   2  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |',\n",
       " '| N/A   78C    P0    35W /  70W |   1711MiB / 15079MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '|   3  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |',\n",
       " '| N/A   75C    P0    33W /  70W |   1717MiB / 15079MiB |      0%      Default |',\n",
       " '+-------------------------------+----------------------+----------------------+',\n",
       " '                                                                               ',\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " '| Processes:                                                       GPU Memory |',\n",
       " '|  GPU       PID   Type   Process name                             Usage      |',\n",
       " '|=============================================================================|',\n",
       " '+-----------------------------------------------------------------------------+',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(subprocess.check_output('nvidia-smi', shell = True)).split('\\\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIBind():\n",
    "    \n",
    "    # Class Initialisation\n",
    "    def __init__(self,\n",
    "                 \n",
    "                 interactions_location = None,\n",
    "                 interactions = None,\n",
    "                 interaction_y_name = 'Y',\n",
    "                 \n",
    "                 drugs_location = None,\n",
    "                 drugs_dataframe = None,\n",
    "                 drug_inchi_name = None,\n",
    "                 drug_smile_name = None,\n",
    "                 \n",
    "                 targets_location = None,\n",
    "                 targets_dataframe = None, \n",
    "                 target_seq_name = None,\n",
    "                 \n",
    "                 mol2vec_location = None,\n",
    "                 mol2vec_model = None,\n",
    "                 \n",
    "                 protvec_location = None, \n",
    "                 protvec_model = None,\n",
    "                 \n",
    "                 nodes_test = None, \n",
    "                 nodes_validation = None, \n",
    "                 \n",
    "                 edges_test = None, \n",
    "                 edges_validation = None, \n",
    "                 \n",
    "                 model_out_dir = None,\n",
    "                 \n",
    "                 debug = False):\n",
    "        \n",
    "        '''\n",
    "         Class initialisation\n",
    "         \n",
    "         Inputs : \n",
    "             \n",
    "             Optional - one of two below\n",
    "                 interactions_location : String - Location of interactions file (CSV / Pickle)\n",
    "                 interactions : Pandas DataFrame - Interactions dataframe\n",
    "             \n",
    "             interaction_y_name : String - Column name for true variable in interactions file\n",
    "\n",
    "             Optional - one of two below\n",
    "                 drugs_location : String - Location of drugs file (CSV / Pickle)\n",
    "                 drugs_dataframe : Pandas DataFrame - Drugs DataFrame\n",
    "             drug_inchi_name : String - Column name of field that contains the InChi Key \n",
    "             drug_smile_name : String - Column name of field that contains the chemical SMILE\n",
    "\n",
    "             Optional - one of two below\n",
    "                 targets_location : String - Location of targets file (CSV / Pickle)\n",
    "                 targets_dataframe : Pandas DataFrame - Targets DataFrame\n",
    "             target_seq_name : String - Column name of field that contains the amino acid sequence\n",
    "\n",
    "             Optional - one of two below\n",
    "                 mol2vec_location : String - Location of Mol2Vec model file\n",
    "                 mol2vec_model : Word2Vec - Word2Vec model\n",
    " \n",
    "             Optional - one of two below\n",
    "                 protvec_location : String - Location of ProtVec model file \n",
    "                 protvec_model : Pandas DataFrame - ProtVec model DataFrame\n",
    "\n",
    "             nodes_test : List - List of DataFrames of test set where all nodes must be unseen in the train set\n",
    "             nodes_validation : List - List of DataFrames of validation set where all nodes must be unseen in the train set\n",
    "\n",
    "             edges_test : List - List of DataFrames of test set where the rows must be unseen in the train set\n",
    "             edges_validation : List - List of DataFrames of validation set where the rows must be unseen in the train set\n",
    "\n",
    "             model_out_dir : String - Path to save trained models\n",
    "             \n",
    "             debug : Bool - Flag to print debug lines\n",
    "         \n",
    "        '''\n",
    "        \n",
    "        # Set Variables\n",
    "        self.interactions_location = interactions_location\n",
    "        self.interactions = interactions\n",
    "        self.interaction_y_name = interaction_y_name\n",
    "        \n",
    "        self.drugs_location = drugs_location\n",
    "        self.drugs_dataframe = drugs_dataframe \n",
    "        self.drug_inchi_name = drug_inchi_name\n",
    "        self.drug_smile_name = drug_smile_name\n",
    "        \n",
    "        self.targets_location = targets_location\n",
    "        self.targets_dataframe = targets_dataframe\n",
    "        self.target_seq_name = target_seq_name\n",
    "        \n",
    "        self.mol2vec_location = mol2vec_location\n",
    "        self.mol2vec_model = mol2vec_model\n",
    "        \n",
    "        self.protvec_location = protvec_location\n",
    "        self.protvec_model = protvec_model\n",
    "        \n",
    "        self.nodes_test = nodes_test\n",
    "        self.nodes_validation = nodes_validation\n",
    "        self.edges_test = edges_test\n",
    "        self.edges_validation = edges_validation\n",
    "        \n",
    "        self.model_out_dir = model_out_dir\n",
    "        \n",
    "        self.debug = debug\n",
    "        \n",
    "        # Read In Drugs \n",
    "        if type(self.drugs_dataframe) == type(None):\n",
    "            self.drugs_dataframe = self.read_input_files(self.drugs_location)\n",
    "        \n",
    "        # Read In Targets\n",
    "        if type(self.targets_dataframe) == type(None):\n",
    "            self.targets_dataframe = self.read_input_files(self.targets_location)\n",
    "\n",
    "        # Create Drug Target Lists\n",
    "        self.drug_list = list(self.drugs_dataframe[self.drug_inchi_name])\n",
    "        self.target_list = list(self.targets_dataframe[self.target_seq_name])\n",
    "        \n",
    "        # Read In Interactions File\n",
    "        if type(self.interactions) == type(None):\n",
    "            self.interactions = self.read_input_files(self.interactions_location)\n",
    "            \n",
    "        # Column Name Assertions \n",
    "        assert self.drug_inchi_name in self.interactions.columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "        assert self.drug_inchi_name in self.drugs_dataframe.columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "        assert self.drug_inchi_name in self.nodes_test[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "        assert self.drug_inchi_name in self.nodes_validation[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "        assert self.drug_inchi_name in self.edges_test[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "        assert self.drug_inchi_name in self.edges_validation[0].columns, \"Please ensure columns with InChi Keys have the same name across all dataframes\"\n",
    "        \n",
    "        assert self.target_seq_name in self.interactions.columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "        assert self.target_seq_name in self.targets_dataframe.columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "        assert self.target_seq_name in self.nodes_test[0].columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "        assert self.target_seq_name in self.nodes_validation[0].columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "        assert self.target_seq_name in self.edges_test[0].columns, \"Please ensure columns with Amino Acid Sequences have the same name across all dataframes\"\n",
    "        assert self.target_seq_name in self.edges_validation[0].columns, \"Please ensure columns withAmino Acid Sequences have the same name across all dataframes\"\n",
    "    \n",
    "    \n",
    "    ###################################################\n",
    "    ############    General Functions      ############\n",
    "    ###################################################\n",
    "    \n",
    "    # Read Input Files \n",
    "    def read_input_files(self, input_location):\n",
    "        \n",
    "        '''\n",
    "        Reads in files into a dataframe given a file location. Currently works with CSV and Pickle files. \n",
    "        \n",
    "        Inputs : \n",
    "            input_location : String - Location of file to read in - accepts only CSV and Pickle files\n",
    "        Outputs : \n",
    "            Pandas DatraFrame \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        assert type(input_location) == type(\"\"), 'Location should be of type str'\n",
    "        \n",
    "        if input_location.split('.')[-1] == 'pkl':\n",
    "            with open(input_location, 'rb') as file: \n",
    "                return pkl.load(file)\n",
    "                \n",
    "        elif input_location.split('.')[-1] == 'csv':\n",
    "            return pd.read_csv(input_location)\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"Unknown input file type, only pkl and csv are supported\")\n",
    "          \n",
    "    def create_test_splits(self):\n",
    "        None\n",
    "    \n",
    "    def create_train_sets(self, unseen_nodes_flag = True, data_leak_check = True):    \n",
    "        \n",
    "        self.train_sets = []\n",
    "        self.train_pos_neg_ratio = []\n",
    "\n",
    "        for i in tqdm(range(len(self.nodes_test))):\n",
    "\n",
    "            # Unseen Targets\n",
    "            unseen_targets = list(set(self.nodes_test[i][self.target_seq_name])) + list(set(self.nodes_validation[i][self.target_seq_name]))\n",
    "            \n",
    "            # Unseen Drugs\n",
    "            unseen_drugs = list(set(self.nodes_test[i][self.drug_inchi_name])) + list(set(self.nodes_validation[i][self.drug_inchi_name]))\n",
    "\n",
    "            # Seen Targets\n",
    "            seen_targets = set(self.targets_dataframe[self.target_seq_name]).difference(unseen_targets)\n",
    "            \n",
    "            # Seen Drugs\n",
    "            seen_drugs = set(drugs[self.drug_inchi_name]).difference(unseen_drugs)\n",
    "\n",
    "            # Seen Targets \n",
    "            seen_target_df = self.interactions[self.interactions[self.target_seq_name].isin(seen_targets)]\n",
    "            seen_target_df = seen_target_df[[self.drug_inchi_name, self.target_seq_name, self.interaction_y_name]]\n",
    "\n",
    "            # Create dataframe with train interactions\n",
    "            # pd.concat + drop duplicates amounts to a set interesection\n",
    "            train_interactions = pd.concat([seen_target_df,\n",
    "                                            self.edges_test[i],\n",
    "                                            self.edges_test[i],\n",
    "                                            self.edges_validation[i],\n",
    "                                            self.edges_validation[i]]).drop_duplicates(keep = False)\n",
    "            \n",
    "            # Ensure unseen nodes if flag is on, else train sets only satisfy unseen targets criteria\n",
    "            if unseen_nodes_flag: \n",
    "                # Ensure Unseen Drugs\n",
    "                train_interactions = train_interactions.reset_index(drop = True)\n",
    "                drop_index = []\n",
    "                for idx, row in tqdm(train_interactions.iterrows()):\n",
    "                    if row[self.drug_inchi_name] in unseen_drugs:\n",
    "                        drop_index.append(idx)\n",
    "                train_interactions.drop(train_interactions.index[drop_index], inplace = True)\n",
    "\n",
    "            self.train_sets.append(train_interactions)\n",
    "            self.train_pos_neg_ratio.append(1 / np.divide(*np.array(train_interactions['Y'].value_counts().values)))\n",
    "            \n",
    "        # Sanity check section\n",
    "        if data_leak_check:\n",
    "            for i in range(len(self.nodes_test)):\n",
    "\n",
    "                print (\"Set : \", i)\n",
    "\n",
    "                # No Overlap Between Unseen Nodes and Train\n",
    "                unseen_targets = list(set(self.nodes_test[i][self.target_seq_name])) + list(set(self.nodes_validation[i][self.target_seq_name]))\n",
    "                print (\"Train - Test - Validation Overlap For Unseen Targets : \", len(list(set(self.train_sets[i][self.target_seq_name]).intersection(unseen_targets))))\n",
    "\n",
    "                if unseen_nodes_flag:\n",
    "                    # No overlap Between Drugs\n",
    "                    unseen_drugs = list(set(self.nodes_test[i][self.drug_inchi_name])) + list(set(self.nodes_validation[i][self.drug_inchi_name]))\n",
    "                    print (\"Train - Test - Validation Overlap For Unseen Drugs : \", len(list(set(self.train_sets[i][self.drug_inchi_name]).intersection(unseen_drugs))))\n",
    "\n",
    "\n",
    "                # No Overlap Between Unseen Edges and Train\n",
    "                train_edges = list(zip(list(self.train_sets[i][self.drug_inchi_name]), list(self.train_sets[i][self.target_seq_name])))\n",
    "                temp_df = pd.concat([self.edges_test[i], self.edges_validation[i]])\n",
    "                test_edges = list(zip(list(temp_df[self.drug_inchi_name]), list(temp_df[self.target_seq_name])))\n",
    "                train_edges = set(train_edges)\n",
    "                test_edges = set(test_edges)\n",
    "                print (\"Train - Test - Validation Overlap For Unseen Edges : \", len(list(train_edges.intersection(test_edges))))\n",
    "\n",
    "                print (\"Train Set : \", self.train_sets[i].shape)\n",
    "                print (\"Nodes Test : \", self.nodes_test[i].shape)\n",
    "                print (\"Nodes Val : \", self.nodes_validation[i].shape)\n",
    "                print (\"Edge Test : \", self.edges_test[i].shape)\n",
    "                print (\"Edge Val : \", self.edges_validation[i].shape)\n",
    "                print (\"Positive / Negatative Ratio : \", self.train_pos_neg_ratio[i])\n",
    "                print (\"\")\n",
    "                \n",
    "    def dataframe_to_embed_array(self, interactions_df, drug_list, target_list, drug_embed_len):\n",
    "    \n",
    "        X_0_list = []\n",
    "        X_1_list = []\n",
    "\n",
    "        skipped_drugs = 0\n",
    "        \n",
    "        # Iterate over all rows in dataframe\n",
    "        for idx, row in interactions_df.iterrows():\n",
    "            \n",
    "            # Get InChiKey and AA Sequence\n",
    "            drug = row[self.drug_inchi_name]\n",
    "            target = row[self.target_seq_name]\n",
    "            \n",
    "            # Get drug index for this drug in drug_list\n",
    "            try:\n",
    "                drug_index = drug_list.index(drug)\n",
    "            except: \n",
    "                drug_index = -1\n",
    "            \n",
    "            # Get target index for this target in target_list\n",
    "            target_index = target_list.index(target)\n",
    "        \n",
    "            # Index into target embedding array and add to X_0\n",
    "            X_0_list.append(self.normalized_target_embeddings[target_index])\n",
    "            \n",
    "            # If drug index not found, add random vector to X_1\n",
    "            if drug_index == -1:\n",
    "                X_1_list.append(np.random.randn(drug_embed_len,))\n",
    "                skipped_drugs = skipped_drugs + 1\n",
    "            else:\n",
    "                # Index into drug embedding array and add to X_1\n",
    "                try:\n",
    "                    X_1_list.append(self.normalized_drug_embeddings[drug_index])\n",
    "                # If drug index not found, add random vector to X_1\n",
    "                except: \n",
    "                    X_1_list.append(np.random.randn(drug_embed_len,))\n",
    "                    skipped_drugs = skipped_drugs + 1\n",
    "        \n",
    "        # Convert lists to arrays\n",
    "        X_0 = np.array(X_0_list)\n",
    "        X_1 = np.array(X_1_list)\n",
    "        Y   = np.array(list(interactions_df['Y']))\n",
    "\n",
    "        if self.debug:\n",
    "            print (\"Number of drugs skipped : \", skipped_drugs)\n",
    "\n",
    "        return X_0, X_1, Y\n",
    "    \n",
    "    def get_validation_results(self, model_name = None, show_plots = True, plot_title = None, num_cols = 2, plot_height = 1500, plot_width = 1500, write_plot_to_html = False, plot_dir = None, plot_name = None):\n",
    "\n",
    "        self.averaged_results = {}\n",
    "        \n",
    "        if type(model_name) == type(None):\n",
    "            model_name = list(self.results.keys())[0]\n",
    "\n",
    "        num_rows = (len(self.train_sets) // num_cols) + (len(self.train_sets) % num_cols)\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows = num_rows, cols = num_cols,\n",
    "            subplot_titles = ['temp' for _ in range(num_rows * num_cols)])\n",
    "\n",
    "        row_counter = 1\n",
    "        col_counter = 1\n",
    "\n",
    "        # Get length of the x axis to ensure avergaes make sense \n",
    "        x_length = [len(self.results[model_name][run]['val_auc_ut']) for run in self.results[model_name].keys()]\n",
    "        # Pick the length that is most common to compute aligned averages\n",
    "        x_length = list(Counter(x_length))[0]\n",
    "\n",
    "        for run in self.results[model_name].keys():\n",
    "\n",
    "            # Plot legend only once\n",
    "            if run == 0:\n",
    "                legend = True\n",
    "            else: \n",
    "                legend = False\n",
    "                \n",
    "            # X axis list\n",
    "            x_list = [x for x in range(len(self.results[model_name][run]['val_auc_ut']))]\n",
    "\n",
    "            # Ensure lengths match up \n",
    "            if len(x_list) == x_length:\n",
    "\n",
    "                # Save validation AUC averaged scores for Unseen Nodes\n",
    "                if 'val_auc_ut' in self.averaged_results:\n",
    "                    self.averaged_results['val_auc_ut'] = self.averaged_results['val_auc_ut'] + np.array(self.results[model_name][run]['val_auc_ut']).reshape(-1, 1)\n",
    "                elif 'val_auc_ut' not in self.averaged_results: \n",
    "                    self.averaged_results['val_auc_ut'] = np.array(self.results[model_name][run]['val_auc_ut']).reshape(-1, 1)\n",
    "\n",
    "                # Save validation AUC averaged scores for Unseen Edges\n",
    "                if 'val_auc_ue' in self.averaged_results:\n",
    "                    self.averaged_results['val_auc_ue'] = self.averaged_results['val_auc_ue'] + np.array(self.results[model_name][run]['val_auc_ue']).reshape(-1, 1)\n",
    "                elif 'val_auc_ue' not in self.averaged_results: \n",
    "                    self.averaged_results['val_auc_ue'] = np.array(self.results[model_name][run]['val_auc_ue']).reshape(-1, 1)\n",
    "\n",
    "                # Save validation AUP averaged scores for Unseen Nodes\n",
    "                if 'val_aup_ut' in self.averaged_results:\n",
    "                    self.averaged_results['val_aup_ut'] = self.averaged_results['val_aup_ut'] + np.array(self.results[model_name][run]['val_aup_ut']).reshape(-1, 1)\n",
    "                elif 'val_aup_ut' not in self.averaged_results: \n",
    "                    self.averaged_results['val_aup_ut'] = np.array(self.results[model_name][run]['val_aup_ut']).reshape(-1, 1)\n",
    "\n",
    "                # Save validation AUP averaged scores for Unseen Edges\n",
    "                if 'val_aup_ue' in self.averaged_results:\n",
    "                    self.averaged_results['val_aup_ue'] = self.averaged_results['val_aup_ue'] + np.array(self.results[model_name][run]['val_aup_ue']).reshape(-1, 1)\n",
    "                elif 'val_aup_ue' not in self.averaged_results: \n",
    "                    self.averaged_results['val_aup_ue'] = np.array(self.results[model_name][run]['val_aup_ue']).reshape(-1, 1)\n",
    "\n",
    "            if show_plots:\n",
    "                # Plot validation AUC for Unseen Nodes    \n",
    "                \n",
    "\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_auc_ut'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUC',\n",
    "                                         line_color = 'deepskyblue',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter )\n",
    "\n",
    "\n",
    "                # Plot validation AUC for Unseen Edges\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_auc_ue'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUC',\n",
    "                                         line_color = 'blue',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter )\n",
    "\n",
    "\n",
    "\n",
    "                # Plot validation AUP for Unseen Nodes\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_aup_ut'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUP',\n",
    "                                         line_color = 'red',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter )\n",
    "\n",
    "\n",
    "                # Plot validation AUP for Unseen Edges\n",
    "                fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = self.results[model_name][run]['val_aup_ue'],\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUP',\n",
    "                                         line_color = 'green',\n",
    "                                         legendgroup = str(run),\n",
    "                                         showlegend = legend),\n",
    "                             row = row_counter,\n",
    "                             col = col_counter)\n",
    "\n",
    "    \n",
    "                fig.update_xaxes(title_text = \"Epochs * Chunks\", row = row_counter, col = col_counter)\n",
    "                fig.update_yaxes(title_text = \"Performance\", row = row_counter, col = col_counter)\n",
    "                fig.layout.annotations[run]['text'] = model_name + \" Run \" + str(run)\n",
    "\n",
    "                if col_counter == num_cols: \n",
    "                    col_counter = 1\n",
    "                    row_counter = row_counter + 1\n",
    "                else: \n",
    "                    col_counter = col_counter + 1\n",
    "\n",
    "            \n",
    "\n",
    "            # Averaged Results Plot\n",
    "            avg_fig = go.Figure()\n",
    "\n",
    "            x_list = [x for x in range(len(self.averaged_results['val_auc_ut']))]\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_auc_ut'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUC',\n",
    "                                         line_color = 'deepskyblue'),\n",
    "                         )\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_auc_ue'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUC',\n",
    "                                         line_color = 'blue'),\n",
    "                         )\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_aup_ut'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Targets AUP',\n",
    "                                         line_color = 'red'),\n",
    "                         )\n",
    "\n",
    "            avg_fig.add_trace(go.Scatter(x = x_list,\n",
    "                                         y = (self.averaged_results['val_aup_ue'] / len(x_list)).ravel(),\n",
    "                                         mode = 'lines',\n",
    "                                         name = 'Unseen Edges AUP',\n",
    "                                         line_color = 'green'),\n",
    "                         )\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        # Optimal epoch\n",
    "        perf = np.zeros((self.averaged_results['val_aup_ue'].shape[0], 4))\n",
    "        ut_c = 0\n",
    "        ut_p = 1\n",
    "        ue_c = 2\n",
    "        ue_p = 3\n",
    "\n",
    "        perf[:, ut_c] = self.averaged_results['val_auc_ut'].ravel()\n",
    "        perf[:, ut_p] = self.averaged_results['val_aup_ut'].ravel()\n",
    "        perf[:, ue_c] = self.averaged_results['val_auc_ue'].ravel()\n",
    "        perf[:, ue_p] = self.averaged_results['val_aup_ue'].ravel()\n",
    "        perf = perf / self.averaged_results['val_aup_ue'].shape[0]\n",
    "\n",
    "        # UT AUC + UE AUC\n",
    "        edge_target = np.argmax(np.sum(perf[:, [ut_c, ue_c]], axis = 1))\n",
    "\n",
    "        # UT AUC + UT AUP\n",
    "        target_only = np.argmax(np.sum(perf[:, [ut_c, ut_p]], axis = 1))\n",
    "\n",
    "        # UE AUC + UE AUP\n",
    "        edge_only = np.argmax(np.sum(perf[:, [ue_c, ue_p]], axis = 1))\n",
    "\n",
    "        print (\"(Epoch * Chunk) With Highest Unseen Node and Edge Score : \", edge_target)\n",
    "        print (\"(Epoch * Chunk) With Highest Unseen Node Score : \", target_only)\n",
    "        print (\"(Epoch * Chunk) With Highest Unseen Edge Score : \", edge_target)\n",
    "        \n",
    "        ut_auc = []\n",
    "        ut_aup = []\n",
    "        ue_auc = []\n",
    "        ue_aup = []\n",
    "\n",
    "        model_key = model_name\n",
    "        best_model = edge_target\n",
    "\n",
    "        for run in self.results[model_key].keys():\n",
    "\n",
    "            ut_auc.append(self.results[model_key][run]['val_auc_ut'][best_model])\n",
    "            ut_aup.append(self.results[model_key][run]['val_aup_ut'][best_model])\n",
    "            ue_auc.append(self.results[model_key][run]['val_auc_ue'][best_model])\n",
    "            ue_aup.append(self.results[model_key][run]['val_aup_ue'][best_model])\n",
    "\n",
    "        print (\"Validation Performance\")\n",
    "        print (\"Best Model Suffix : \", self.model_name_index[model_name][best_model])\n",
    "        print (\"Unseen Node AUC : \", np.mean(ut_auc), \"+/-\", np.std(ut_auc))\n",
    "        print (\"Unseen Node AUP : \", np.mean(ut_aup), \"+/-\", np.std(ut_aup))\n",
    "        print (\"Unseen Edges AUC : \", np.mean(ue_auc), \"+/-\", np.std(ue_auc))\n",
    "        print (\"Unseen Edges AUP : \", np.mean(ue_aup), \"+/-\", np.std(ue_aup))\n",
    "        \n",
    "        self.optimal_validation_model = best_model\n",
    "        \n",
    "        \n",
    "        if show_plots:\n",
    "            fig.update_layout(title_text = plot_title, \n",
    "                                  height = plot_height,\n",
    "                                  width = plot_width,\n",
    "                                  showlegend = True)\n",
    "            fig.show()\n",
    "            \n",
    "            avg_fig.update_layout(title_text = plot_title + \" - Averaged Results Across \" + str(len(x_list)) + \" Runs\", \n",
    "                              xaxis_title_text = 'Epochs * Chunks',\n",
    "                              yaxis_title_text = 'Performance',\n",
    "                              showlegend = True)\n",
    "            avg_fig.show()\n",
    "\n",
    "            if write_plot_to_html:\n",
    "                fig.write_html(plot_dir.rstrip('/') + plot_name + '_k_fold_split_plots.html')\n",
    "                avg_fig.write_html(plot_dir.rstrip('/') + plot_name + '_averaged_results_plots.html')\n",
    "\n",
    "    def get_test_results(self, model_name = None, optimal_validation_model = None, drug_filter_list = [], target_filter_list = []):\n",
    "        \n",
    "        # Initialise dictionary\n",
    "        try: \n",
    "            self.test_results\n",
    "        except: \n",
    "            self.test_results = {}\n",
    "            \n",
    "        if type(model_name) == type(None):\n",
    "                model_name = list(self.results.keys())[0]\n",
    "        if type(optimal_validation_model) == type(None):    \n",
    "            optimal_validation_model = self.optimal_validation_model\n",
    "            \n",
    "        if model_name not in self.test_results.keys():\n",
    "            self.test_results[model_name] = {}\n",
    "        \n",
    "        for run_number in range(len(self.train_sets)):\n",
    "                \n",
    "            model_prefix = \"_\".join(os.listdir(self.model_out_dir.rstrip('/') + '/Run_' + str(run_number))[0].split('_')[:-4])\n",
    "            model_suffix = self.model_name_index[model_name][optimal_validation_model]\n",
    "            model_location = model_prefix + model_suffix\n",
    "            \n",
    "            drug_embed_len = self.normalized_drug_embeddings[0].shape[0]\n",
    "            \n",
    "            filtered_nodes_test = self.nodes_test[run_number]\n",
    "            filtered_edges_test = self.edges_test[run_number]\n",
    "            \n",
    "            if drug_filter_list != [] and target_filter_list != []:\n",
    "                filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.drug_inchi_name].isin(drug_filter_list)) & (filtered_nodes_test[self.target_seq_name].isin(target_filter_list))]\n",
    "                filtered_edges_test = filtered_edges_test[(filtered_edges_test[self.drug_inchi_name].isin(drug_filter_list)) & (filtered_edges_test[self.target_seq_name].isin(target_filter_list))]\n",
    "            \n",
    "            elif drug_filter_list != [] and target_filter_list == []:\n",
    "                filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.drug_inchi_name].isin(drug_filter_list))]\n",
    "                filtered_edges_test = filtered_edges_test[(filtered_edges_test[self.drug_inchi_name].isin(drug_filter_list))]\n",
    "            \n",
    "            elif drug_filter_list == [] and target_filter_list != []:\n",
    "                filtered_nodes_test = filtered_nodes_test[(filtered_nodes_test[self.target_seq_name].isin(target_filter_list))]\n",
    "                filtered_edges_test = filtered_edges_test[(filtered_edges_test[self.target_seq_name].isin(target_filter_list))]\n",
    "            \n",
    "            else: \n",
    "                None\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            X_0_test_ut, X_1_test_ut, Y_test_actual_ut = self.dataframe_to_embed_array(interactions_df = filtered_nodes_test,\n",
    "                                                                              drug_list = self.drug_list,\n",
    "                                                                              target_list = self.target_list,\n",
    "                                                                              drug_embed_len = drug_embed_len)\n",
    "\n",
    "            X_0_test_ue, X_1_test_ue, Y_test_actual_ue = self.dataframe_to_embed_array(interactions_df = filtered_edges_test,\n",
    "                                                                                  drug_list = self.drug_list,\n",
    "                                                                                  target_list = self.target_list,\n",
    "                                                                                  drug_embed_len = drug_embed_len)\n",
    "            \n",
    "            model = load_model(self.model_out_dir.rstrip('/') + '/Run_' + str(run_number) + '/' + model_location)\n",
    "\n",
    "            # Test on unseen nodes\n",
    "            Y_test_predictions_ut = []\n",
    "            Y_test_predictions_ut.extend(model.predict([X_0_test_ut, X_1_test_ut]))\n",
    "            Y_test_predictions_ut = [x[0] if not np.isnan(x[0]) else 0 for x in Y_test_predictions_ut]\n",
    "\n",
    "            true = Y_test_actual_ut\n",
    "            pred = Y_test_predictions_ut\n",
    "\n",
    "            f1_scores = []\n",
    "\n",
    "            for j in np.arange(0.0, 1.0, 0.01):\n",
    "                f1_scores.append(f1_score(true, [1 if (i > j) else 0 for i in pred]))\n",
    "\n",
    "            f_1_thresh = [idx for idx, x in list(zip(np.arange(0.0, 1.0, 0.01), f1_scores)) if x == max(f1_scores)][0]\n",
    "\n",
    "            pred_bin = [1 if (i > f_1_thresh) else 0 for i in pred]\n",
    "\n",
    "                \n",
    "            try: \n",
    "                self.test_results[model_name][run_number]\n",
    "            except:\n",
    "                self.test_results[model_name][run_number] = {}\n",
    "\n",
    "            self.test_results[model_name][run_number]['unseen_targets_auc'] = roc_auc_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_targets_aup'] = average_precision_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_targets_f1_scores'] = f1_scores\n",
    "            self.test_results[model_name][run_number]['unseen_targets_max_f1'] = np.max(f1_scores)\n",
    "            self.test_results[model_name][run_number]['unseen_targets_f1_threshold'] = f_1_thresh\n",
    "            self.test_results[model_name][run_number]['targets_confusion_matrix'] = confusion_matrix(true, pred_bin)\n",
    "            \n",
    "            # Test on unseen edges\n",
    "            Y_test_predictions_ue = []\n",
    "            Y_test_predictions_ue.extend(model.predict([X_0_test_ue, X_1_test_ue]))\n",
    "            Y_test_predictions_ue = [x[0] if not np.isnan(x[0]) else 0 for x in Y_test_predictions_ue]\n",
    "\n",
    "            true = Y_test_actual_ue\n",
    "            pred = Y_test_predictions_ue\n",
    "\n",
    "            f1_scores = []\n",
    "\n",
    "            for j in np.arange(0.0, 1.0, 0.01):\n",
    "                f1_scores.append(f1_score(true, [1 if (i > j) else 0 for i in pred]))\n",
    "\n",
    "            f_1_thresh = [idx for idx, x in list(zip(np.arange(0.0, 1.0, 0.01), f1_scores)) if x == max(f1_scores)][0]\n",
    "\n",
    "            pred_bin = [1 if (i > f_1_thresh) else 0 for i in pred]\n",
    "\n",
    "            self.test_results[model_name][run_number]['unseen_edges_auc'] = roc_auc_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_edges_aup'] = average_precision_score(true, pred)\n",
    "            self.test_results[model_name][run_number]['unseen_edges_f1_scores'] = f1_scores\n",
    "            self.test_results[model_name][run_number]['unseen_edges_max_f1'] = np.max(f1_scores)\n",
    "            self.test_results[model_name][run_number]['unseen_edges_f1_threshold'] = f_1_thresh\n",
    "            self.test_results[model_name][run_number]['edges_confusion_matrix'] = confusion_matrix(true, pred_bin)\n",
    "            \n",
    "        ue_auc = []\n",
    "        ue_aup = []\n",
    "        ut_auc = []\n",
    "        ut_aup = []\n",
    "        f1_t_e = []\n",
    "        f1_t_t = []\n",
    "        f1_t = []\n",
    "        f1_e = []\n",
    "\n",
    "        conf_t = []\n",
    "        conf_e = []\n",
    "\n",
    "\n",
    "        for run_number in self.test_results[model_name].keys():\n",
    "            \n",
    "            # Averaged confusion matrix \n",
    "            conf_tot_t = np.sum(self.test_results[model_name][run_number]['targets_confusion_matrix'], axis = 0)\n",
    "            conf_tot_e = np.sum(self.test_results[model_name][run_number]['edges_confusion_matrix'], axis = 0)\n",
    "\n",
    "            ue_auc.append(self.test_results[model_name][run_number]['unseen_edges_auc'])\n",
    "            ue_aup.append(self.test_results[model_name][run_number]['unseen_edges_aup'])\n",
    "            ut_auc.append(self.test_results[model_name][run_number]['unseen_targets_auc'])\n",
    "            ut_aup.append(self.test_results[model_name][run_number]['unseen_targets_aup'])\n",
    "            f1_t_e.append(self.test_results[model_name][run_number]['unseen_edges_f1_threshold'])\n",
    "            f1_t_t.append(self.test_results[model_name][run_number]['unseen_targets_f1_threshold'])    \n",
    "            f1_t.append(self.test_results[model_name][run_number]['unseen_targets_max_f1'])\n",
    "            f1_e.append(self.test_results[model_name][run_number]['unseen_edges_max_f1'])\n",
    "            if self.test_results[model_name][run_number]['targets_confusion_matrix'][0][0] != 0:\n",
    "                conf_t.append(self.test_results[model_name][run_number]['targets_confusion_matrix'] / conf_tot_t)\n",
    "                conf_e.append(self.test_results[model_name][run_number]['edges_confusion_matrix'] / conf_tot_e)\n",
    "        \n",
    "        # Compute mean and deviation for the confusion matrix \n",
    "        target_conf = np.zeros((2, 2), dtype = object)\n",
    "        t_conf_mean = np.mean(conf_t, axis = 0)\n",
    "        t_conf_err = np.std(conf_t, axis = 0)\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                target_conf[i][j] = str(np.round(t_conf_mean[i][j], 2)) + \" +/- \" + str(np.round(t_conf_err[i][j], 2))\n",
    "        target_conf = pd.DataFrame(target_conf) \n",
    "\n",
    "        print (\"Test Set Performance : \")\n",
    "        print (\"\")\n",
    "        print (\"\\tUnseen Nodes : \\n\")\n",
    "        print (\"\\t\\tAUC          : \", np.mean(ut_auc), \"+/-\", np.std(ut_auc))\n",
    "        print (\"\\t\\tAUP          : \", np.mean(ut_aup), \"+/-\", np.std(ut_aup))\n",
    "        print (\"\\t\\tMax F1 Score : \", np.mean(f1_t), \"+/-\", np.std(f1_t))\n",
    "        print (\"\\t\\tF1 Threshold : \", np.mean(f1_t_t), \"+/-\", np.std(f1_t_t))\n",
    "        print (\"\\t\\tConfusion Matrix : \")\n",
    "        target_conf.columns = ['Pred (0)', 'Pred (1)']\n",
    "        target_conf.index = ['True (0)', 'True (1)']\n",
    "        display(target_conf)\n",
    "        \n",
    "        # Compute mean and deviation for the confusion matrix \n",
    "        edge_conf = np.zeros((2, 2), dtype = object)\n",
    "        e_conf_mean = np.mean(conf_e, axis = 0)\n",
    "        e_conf_err = np.std(conf_e, axis = 0)\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                edge_conf[i][j] = str(np.round(e_conf_mean[i][j], 2)) + \" +/- \" + str(np.round(e_conf_err[i][j], 2))\n",
    "        edge_conf = pd.DataFrame(edge_conf) \n",
    "\n",
    "        print (\"\")\n",
    "        print (\"\\tUnseen Edges : \\n\")\n",
    "        print (\"\\t\\tAUC          : \", np.mean(ue_auc), \"+/-\", np.std(ue_auc))\n",
    "        print (\"\\t\\tAUP          : \", np.mean(ue_aup), \"+/-\", np.std(ue_aup))\n",
    "        print (\"\\t\\tMax F1 Score : \", np.mean(f1_e), \"+/-\", np.std(f1_e))\n",
    "        print (\"\\t\\tF1 Threshold : \", np.mean(f1_t_e), \"+/-\", np.std(f1_t_e))\n",
    "        print (\"\\t\\tConfusion Matrix : \")\n",
    "        edge_conf.columns = ['Pred (0)', 'Pred (1)']\n",
    "        edge_conf.index = ['True (0)', 'True (1)']\n",
    "        display(edge_conf)\n",
    "\n",
    "        \n",
    "    ###################################################\n",
    "    ############ VecNet Specific Functions ############\n",
    "    ###################################################\n",
    "    \n",
    "    # Get Drug Embeddings From Mol2Vec\n",
    "    def get_mol2vec_embeddings(self, embedding_dimension = 300, replace_dataframe = True, return_normalisation_conststants = False):\n",
    "        \n",
    "        '''\n",
    "        Generate Mol2Vec embeddings for all drugs in the drugs dataframe \n",
    "        \n",
    "        Inputs : \n",
    "            embedding_dimension : Integer - Number of dimensions the Mol2Vec model expects\n",
    "            replace_dataframe : Bool - Replace existing drugs dataframe with one that contains InChi Key and its respective normalised Mol2Vec embedding\n",
    "            return_normalisation_conststants : Bool - Returns normalisation constant if true\n",
    "        \n",
    "        Outputs (optional): \n",
    "            centered_drug_embeddings : Numpy Array\n",
    "            centered_drug_embeddings_length : Float\n",
    "            normalized_drug_embeddings : Numpy Array\n",
    "        '''\n",
    "        \n",
    "        # Create dictionary to hold drug_inchi : drug_smile\n",
    "        drug_smiles = {}\n",
    "\n",
    "        for index, row in tqdm(self.drugs_dataframe.iterrows()):\n",
    "\n",
    "            drug_id = row[self.drug_inchi_name]\n",
    "            drug_smile = row[self.drug_smile_name]\n",
    "\n",
    "            drug_smiles[drug_id] = drug_smile\n",
    "\n",
    "        # Read in Mol2Vec model\n",
    "        if type(self.mol2vec_model) == type(None):\n",
    "            self.mol2vec_model = word2vec.Word2Vec.load(self.mol2vec_location)\n",
    "        \n",
    "        # Create empty array to hold embeddings\n",
    "        drug_embeddings = np.zeros((len(drug_smiles.keys()), embedding_dimension))\n",
    "        miss_words = []\n",
    "        hit_words = 0\n",
    "        bad_mol = 0\n",
    "        percent_unknown = []\n",
    "    \n",
    "        # Iterate over all drugs in dataset\n",
    "        for idx, drug in tqdm(enumerate(drug_smiles.keys())):\n",
    "            flag = 0\n",
    "            mol_miss_words = 0\n",
    "            \n",
    "            # Create molecule object from smiles\n",
    "            molecule = Chem.MolFromSmiles(drug_smiles[drug])\n",
    "            try:\n",
    "                # Get fingerprint from molecule\n",
    "                sub_structures = mol2alt_sentence(molecule, 2)\n",
    "            except Exception as e: \n",
    "                if self.debug: \n",
    "                    print (e)\n",
    "                percent_unknown.append(100)\n",
    "                continue    \n",
    "            \n",
    "            # Iterate over each sub structure\n",
    "            for sub in sub_structures:\n",
    "                # Check to see if substructure exists\n",
    "                try:\n",
    "                    drug_embeddings[idx, :] = drug_embeddings[idx, :] + self.mol2vec_model.wv[sub]\n",
    "                    hit_words = hit_words + 1\n",
    "                \n",
    "                # If not, replace with UNK (unknown)\n",
    "                except Exception as e:\n",
    "                    if self.debug : \n",
    "                        print (\"Sub structure not found\")\n",
    "                        print (e)\n",
    "                    drug_embeddings[idx, :] = drug_embeddings[idx, :] + self.mol2vec_model.wv['UNK']\n",
    "                    miss_words.append(sub)\n",
    "                    flag = 1\n",
    "                    mol_miss_words = mol_miss_words + 1\n",
    "\n",
    "            percent_unknown.append((mol_miss_words / len(sub_structures)) * 100)\n",
    "\n",
    "            if flag == 1:\n",
    "                bad_mol = bad_mol + 1 \n",
    "        \n",
    "        # Normalise embeddings\n",
    "        self.centered_drug_embeddings = drug_embeddings - np.mean(drug_embeddings, axis = 0)\n",
    "        self.centered_drug_embeddings_length = np.mean(np.sqrt(np.sum(self.centered_drug_embeddings * self.centered_drug_embeddings, axis = 1)))\n",
    "        self.normalized_drug_embeddings = self.centered_drug_embeddings / np.expand_dims(self.centered_drug_embeddings_length, axis = -1)\n",
    "\n",
    "        # Replace drugs dataframe with one with two columns - InChi Key and 'normalized_embeddings'\n",
    "        if replace_dataframe: \n",
    "            self.drugs_dataframe = pd.DataFrame([list(drug_smiles.keys()), self.normalized_drug_embeddings]).T\n",
    "            self.drugs_dataframe.columns = [self.drug_inchi_name, 'normalized_embeddings']\n",
    "            self.drug_list = list(self.drugs_dataframe[self.drug_inchi_name])\n",
    "        \n",
    "        # Return normalized constants and values to save\n",
    "        if return_normalisation_conststants: \n",
    "            return self.centered_drug_embeddings, self.centered_drug_embeddings_length, self.normalized_drug_embeddings\n",
    "    \n",
    "    # Get Target Embeddings From ProtVec\n",
    "    def get_protvec_embeddings(self, embedding_dimension = 100, replace_dataframe = True, return_normalisation_conststants = False, delimiter = '\\t'):\n",
    "        \n",
    "        # Read in ProtVec model\n",
    "        if type(self.protvec_model) == type(None): \n",
    "            self.protvec_model = pd.read_csv(self.protvec_location, delimiter = delimiter)\n",
    "            \n",
    "        # Create dictionary of words : values for faster indexing\n",
    "        trigram_dict = {}\n",
    "        for idx, row in tqdm(self.protvec_model.iterrows()):\n",
    "\n",
    "            trigram_dict[row['words']] = self.protvec_model.iloc[idx, 1:].values.astype(np.float)\n",
    "\n",
    "        trigram_list = set(trigram_dict.keys())\n",
    "\n",
    "        self.target_embeddings = np.zeros((len(self.target_list), embedding_dimension))\n",
    "        length_of_target = [0 for _ in range(len(self.target_list))]\n",
    "        \n",
    "        # For each target in target list\n",
    "        for idx, target in tqdm(enumerate(self.target_list)):\n",
    "\n",
    "            n = 3\n",
    "            split_by_three = [target[i : i + n] for i in range(0, len(target), n)]\n",
    "            length_of_target[idx] = len(split_by_three)\n",
    "\n",
    "            for trigram in split_by_three: \n",
    "\n",
    "                if len(trigram) == 2: \n",
    "                    trigram = \"X\" + trigram\n",
    "\n",
    "                elif len(trigram) == 1:\n",
    "                    trigram = \"XX\" + trigram\n",
    "\n",
    "                if trigram in trigram_list:\n",
    "                    self.target_embeddings[idx, :] = self.target_embeddings[idx, :] + trigram_dict[trigram]\n",
    "        \n",
    "        self.centered_target_embeddings = self.target_embeddings - np.mean(self.target_embeddings, axis = 0)\n",
    "        self.centered_target_embeddings_length = np.mean(np.sqrt(np.sum(self.centered_target_embeddings * self.centered_target_embeddings, axis = 1)))\n",
    "        self.normalized_target_embeddings = self.centered_target_embeddings / np.expand_dims(self.centered_target_embeddings_length, axis = -1)\n",
    "        \n",
    "        # Replace targets dataframe with \n",
    "        if replace_dataframe: \n",
    "            self.targets_dataframe = pd.DataFrame([self.target_list, self.normalized_target_embeddings]).T\n",
    "            self.targets_dataframe.columns = [self.target_seq_name, 'normalized_embeddings']\n",
    "        \n",
    "        if return_normalisation_conststants:\n",
    "            return self.target_embeddings, self.centered_target_embeddings_length, self.normalized_target_embeddings\n",
    " \n",
    "    def vecnet_2048_2048_concat_512_512(self):\n",
    "    \n",
    "        target_input = Input(shape = (100,))\n",
    "        X_0 = Dense(2048, kernel_initializer = glorot_uniform(), activation = 'relu')(target_input)\n",
    "\n",
    "        drugs_input = Input(shape = (300,))\n",
    "        X_1 = Dense(2048, kernel_initializer = glorot_uniform(), activation = 'relu')(drugs_input)\n",
    "\n",
    "        combined = Concatenate(axis = -1)([X_0, X_1])\n",
    "        X = Dropout(0.5)(combined)\n",
    "\n",
    "        X = Dense(512, kernel_initializer = glorot_uniform())(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = Dense(512, kernel_initializer = glorot_uniform())(X)\n",
    "        X = Activation('relu')(X)\n",
    "\n",
    "        X = Dense(1, kernel_initializer = glorot_uniform())(X)\n",
    "        X = Activation('sigmoid')(X)\n",
    "\n",
    "        model = Model(inputs = [target_input, drugs_input] , outputs = X)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def train_vecnet(self, model_name, epochs, version = None, learning_rate = 0.00001, beta_1 = 0.9, beta_2 = 0.999, batch_size = 16, chunk_test_frequency = 250):\n",
    "        \n",
    "        self.normalized_target_embeddings = np.array(list(self.targets_dataframe['normalized_embeddings']))\n",
    "        self.normalized_drug_embeddings = np.array(list(self.drugs_dataframe['normalized_embeddings']))\n",
    "        \n",
    "        # Check if variable exists\n",
    "        try:\n",
    "            self.results\n",
    "        except:\n",
    "            self.results = {}\n",
    "        try:\n",
    "            self.model_name_index\n",
    "        except:\n",
    "            self.model_name_index = {}\n",
    "        \n",
    "        if type(version) == type(None):\n",
    "            version = input(\"Version : \")\n",
    "        version = str(version)\n",
    "        v_num = version\n",
    "        \n",
    "        # Iterate over k folds\n",
    "        for run_number in tqdm(range(len(self.train_sets))):\n",
    "            \n",
    "            # Set class weights to reflect train set positive to negative ratio\n",
    "            class_weight = {0: self.train_pos_neg_ratio[run_number],\n",
    "                            1: 1}\n",
    "            \n",
    "            # Create Lists To Hold Information\n",
    "            val_auc_ut = []\n",
    "            val_auc_ue = []\n",
    "            val_aup_ut = []\n",
    "            val_aup_ue = []\n",
    "\n",
    "            loss = []\n",
    "            acc = []\n",
    "\n",
    "            # Reinitialise Model At Each Run \n",
    "            model = self.vecnet_2048_2048_concat_512_512()\n",
    "            model_optimizer = tensorflow.keras.optimizers.Adam(lr = learning_rate, beta_1 = beta_1, beta_2 = beta_2, amsgrad = False)\n",
    "            model.compile(loss = 'binary_crossentropy', optimizer = model_optimizer, metrics = ['binary_accuracy'])\n",
    "\n",
    "            # Create TQDM Object So We Can Play With Printed String\n",
    "            t = tqdm(np.random.choice(range(epochs), epochs, replace = False))\n",
    "            \n",
    "            # Create File Name To Save Model\n",
    "            version = v_num + \"_run\" + str(run_number) + \"_\" + pd.to_datetime(time.time(), unit = 's').strftime('%m-%d_%Hh%M')\n",
    "\n",
    "            # Create Validation DataFrames For Each Run\n",
    "            drug_embed_len = self.normalized_drug_embeddings[0].shape[0]\n",
    "            \n",
    "            X_0_val_ut, X_1_val_ut, Y_val_actual_ut = self.dataframe_to_embed_array(interactions_df = self.nodes_validation[run_number],\n",
    "                                                                                  drug_list = self.drug_list,\n",
    "                                                                                  target_list = self.target_list,\n",
    "                                                                                  drug_embed_len = drug_embed_len)\n",
    "\n",
    "            X_0_val_ue, X_1_val_ue, Y_val_actual_ue = self.dataframe_to_embed_array(interactions_df = self.edges_validation[run_number],\n",
    "                                                                                  drug_list = self.drug_list,\n",
    "                                                                                  target_list = self.target_list,\n",
    "                                                                                  drug_embed_len = drug_embed_len)\n",
    "\n",
    "            # Create Variable For Seen Targets Needed Later\n",
    "            seen_targets = list(self.train_sets[run_number][self.target_seq_name])\n",
    "            \n",
    "            # Counter to keep track of model names during testing\n",
    "            model_index_counter = 0\n",
    "            \n",
    "            model_key = model_name + '_v' + str(v_num)\n",
    "            if model_key not in self.model_name_index.keys():\n",
    "                self.model_name_index[model_key] = {}\n",
    "            \n",
    "            \n",
    "            # For Each Epoch\n",
    "            for ep, i in enumerate(t):\n",
    "\n",
    "\n",
    "                # Slice Into Chunks\n",
    "                interactions_sliced = np.array_split(self.train_sets[run_number], len(self.train_sets[run_number]) / 500)\n",
    "                \n",
    "                # Train On Each Chunk\n",
    "                for idx, interaction in enumerate(interactions_sliced):\n",
    "\n",
    "                    output_string = \"\"\n",
    "\n",
    "                    X_0, X_1, Y = self.dataframe_to_embed_array(interactions_df = interaction,\n",
    "                                                           drug_list = self.drug_list, \n",
    "                                                           target_list = self.target_list,\n",
    "                                                           drug_embed_len = drug_embed_len)\n",
    "\n",
    "                    history = model.fit([X_0, X_1], Y,\n",
    "                                          batch_size = batch_size,\n",
    "                                          epochs = 1,\n",
    "                                          class_weight = class_weight,\n",
    "                                          verbose = 0)\n",
    "\n",
    "                    if idx % chunk_test_frequency == 0:\n",
    "\n",
    "                        # Calculate and Save Unseen Target Performance\n",
    "                        Y_val_predictions_ut = []\n",
    "                        Y_val_predictions_ut.extend(model.predict([X_0_val_ut, X_1_val_ut]))\n",
    "                        Y_val_predictions_ut = [x[0] for x in Y_val_predictions_ut]\n",
    "                        curr_val_auc = roc_auc_score(Y_val_actual_ut, Y_val_predictions_ut)\n",
    "                        curr_val_aup = average_precision_score(Y_val_actual_ut, Y_val_predictions_ut)\n",
    "                        val_auc_ut.append(curr_val_auc)\n",
    "                        val_aup_ut.append(curr_val_aup)\n",
    "\n",
    "                        Y_val_predictions_ue = []\n",
    "                        Y_val_predictions_ue.extend(model.predict([X_0_val_ue, X_1_val_ue]))\n",
    "                        Y_val_predictions_ue = [x[0] for x in Y_val_predictions_ue]\n",
    "                        curr_val_auc = roc_auc_score(Y_val_actual_ue, Y_val_predictions_ue)\n",
    "                        curr_val_aup = average_precision_score(Y_val_actual_ue, Y_val_predictions_ue)\n",
    "                        val_aup_ue.append(curr_val_aup)\n",
    "                        val_auc_ue.append(curr_val_auc)\n",
    "\n",
    "                        # Print Stuff\n",
    "                        output_string = output_string + \"Unseen Nodes AUC : \" + str(np.round(val_auc_ut[-1], 2)) + \"\\nUnseen Edges AUC : \" +  str(np.round(val_auc_ue[-1], 2)) + \"\\n\"\n",
    "                        output_string = output_string + \"Unseen Nodes AUP : \" + str(np.round(val_aup_ut[-1], 2)) + \"\\nUnseen Edges AUP : \" +  str(np.round(val_aup_ue[-1], 2)) + \"\\n\"\n",
    "\n",
    "                        # Save Model\n",
    "                        if not os.path.isdir(self.model_out_dir.rstrip('/') + '/Run_' + str(run_number)):\n",
    "                            os.mkdir(self.model_out_dir.rstrip('/') + '/Run_' + str(run_number))\n",
    "                        model.save(self.model_out_dir.rstrip('/') + '/Run_' + str(run_number) + '/' + model_name + str(version) + \"_epoch_\" + str(ep) + \"_idx_\" + str(idx) + '.model')\n",
    "                        \n",
    "                        self.model_name_index[model_key][model_index_counter] = \"_epoch_\" + str(ep) + \"_idx_\" + str(idx) + '.model'\n",
    "                        model_index_counter = model_index_counter + 1\n",
    "                        \n",
    "                        t.write(output_string)\n",
    "\n",
    "                        loss = loss + history.history['loss']\n",
    "                        acc = acc + history.history['binary_accuracy']\n",
    "                        \n",
    "            \n",
    "    \n",
    "            try:\n",
    "                self.results[model_key]\n",
    "            except: \n",
    "                self.results[model_key] = {}\n",
    "\n",
    "            self.results[model_key][run_number] = {}\n",
    "            self.results[model_key][run_number]['val_auc_ut'] = val_auc_ut\n",
    "            self.results[model_key][run_number]['val_auc_ue'] = val_auc_ue\n",
    "            self.results[model_key][run_number]['val_aup_ut'] = val_aup_ut\n",
    "            self.results[model_key][run_number]['val_aup_ue'] = val_aup_ue\n",
    "            self.results[model_key][run_number]['loss'] = loss\n",
    "            self.results[model_key][run_number]['acc'] = acc  \n",
    "            \n",
    "            with open(self.model_out_dir.rstrip('/') + '/results_' + str(v_num) + '.json', 'w') as file: \n",
    "                json.dump(self.results, file)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VecNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/sars-busters-consolidated/interactions/targets_test.pkl', 'rb') as file: \n",
    "    nodes_test = pkl.load(file)\n",
    "    \n",
    "with open('/data/sars-busters-consolidated/interactions/targets_validation.pkl', 'rb') as file: \n",
    "    nodes_validation = pkl.load(file)\n",
    "    \n",
    "with open('/data/sars-busters-consolidated/interactions/edges_test.pkl', 'rb') as file: \n",
    "    edges_test = pkl.load(file)\n",
    "    \n",
    "with open('/data/sars-busters-consolidated/interactions/edges_validation.pkl', 'rb') as file: \n",
    "    edges_validation = pkl.load(file)\n",
    "    \n",
    "with open('/data/sars-busters/Mol2Vec/chemicals_01_w_embed.pkl', 'rb') as file: \n",
    "    drugs = pkl.load(file)\n",
    "    \n",
    "with open('/data/sars-busters/Mol2Vec/amino_01_w_embed.pkl', 'rb') as file: \n",
    "    targets = pkl.load(file)\n",
    "    \n",
    "    \n",
    "drugs = drugs.rename(columns = {'Label' : 'InChiKey'})\n",
    "targets = targets.rename(columns = {'Label' : 'target_aa_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vecnet_object = AIBind(interactions_location = '/data/sars-busters-consolidated/interactions/dataset_2_filtered.csv',\n",
    "                       interaction_y_name = 'Y',\n",
    "                       drugs_location = None,\n",
    "                       drugs_dataframe = drugs,\n",
    "                       drug_inchi_name = 'InChiKey',\n",
    "                       targets_location = None,\n",
    "                       targets_dataframe = targets, \n",
    "                       target_seq_name = 'target_aa_code',\n",
    "                       drug_smile_name = 'SMILE',\n",
    "                       mol2vec_location = '/data/sars-busters/Mol2Vec/model_300dim.pkl',\n",
    "                       protvec_location = '/home/sars-busters/Mol2Vec/Results/protVec_100d_3grams.csv',\n",
    "                       nodes_test = nodes_test,\n",
    "                       nodes_validation = nodes_validation,\n",
    "                       edges_test = edges_test,\n",
    "                       edges_validation = edges_validation,\n",
    "                       model_out_dir = './',\n",
    "                       debug = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48efdda77e5d4ee88ee5442f4c277f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f177ce07bafd49758455cfe00f487028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eee7d8af00425294e4fe379ca8f368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c30bafa525a437ab834a0df36e3bac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8de6387ab84ac3ab2418a6e5768e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f8e1a8b95e405dbdad7e605fe9c736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a26c85c8e2346779751f9463c792f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20189e4337f24d149f158bb110ffbaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5d1ce52b3d4b63bd4766f3626ccb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad7303a7733418394f40c6223f61525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ba6f6c5ac042479b066138fc0fed76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set :  0\n",
      "Train - Test - Validation Overlap For Unseen Targets :  0\n",
      "Train - Test - Validation Overlap For Unseen Drugs :  0\n",
      "Train - Test - Validation Overlap For Unseen Edges :  0\n",
      "Train Set :  (14005, 3)\n",
      "Nodes Test :  (5473, 3)\n",
      "Nodes Val :  (5474, 3)\n",
      "Edge Test :  (3843, 3)\n",
      "Edge Val :  (3843, 3)\n",
      "Positive / Negatative Ratio :  0.5287632354546448\n",
      "\n",
      "Set :  1\n",
      "Train - Test - Validation Overlap For Unseen Targets :  0\n",
      "Train - Test - Validation Overlap For Unseen Drugs :  0\n",
      "Train - Test - Validation Overlap For Unseen Edges :  0\n",
      "Train Set :  (10716, 3)\n",
      "Nodes Test :  (5755, 3)\n",
      "Nodes Val :  (5755, 3)\n",
      "Edge Test :  (3759, 3)\n",
      "Edge Val :  (3759, 3)\n",
      "Positive / Negatative Ratio :  0.5899109792284867\n",
      "\n",
      "Set :  2\n",
      "Train - Test - Validation Overlap For Unseen Targets :  0\n",
      "Train - Test - Validation Overlap For Unseen Drugs :  0\n",
      "Train - Test - Validation Overlap For Unseen Edges :  0\n",
      "Train Set :  (14871, 3)\n",
      "Nodes Test :  (5460, 3)\n",
      "Nodes Val :  (5461, 3)\n",
      "Edge Test :  (3847, 3)\n",
      "Edge Val :  (3847, 3)\n",
      "Positive / Negatative Ratio :  0.5734842873769972\n",
      "\n",
      "Set :  3\n",
      "Train - Test - Validation Overlap For Unseen Targets :  0\n",
      "Train - Test - Validation Overlap For Unseen Drugs :  0\n",
      "Train - Test - Validation Overlap For Unseen Edges :  0\n",
      "Train Set :  (15804, 3)\n",
      "Nodes Test :  (5087, 3)\n",
      "Nodes Val :  (5087, 3)\n",
      "Edge Test :  (3959, 3)\n",
      "Edge Val :  (3959, 3)\n",
      "Positive / Negatative Ratio :  0.6020273694880892\n",
      "\n",
      "Set :  4\n",
      "Train - Test - Validation Overlap For Unseen Targets :  0\n",
      "Train - Test - Validation Overlap For Unseen Drugs :  0\n",
      "Train - Test - Validation Overlap For Unseen Edges :  0\n",
      "Train Set :  (12006, 3)\n",
      "Nodes Test :  (5632, 3)\n",
      "Nodes Val :  (5633, 3)\n",
      "Edge Test :  (3795, 3)\n",
      "Edge Val :  (3795, 3)\n",
      "Positive / Negatative Ratio :  0.6487228783301291\n",
      "\n",
      "Set :  5\n",
      "Train - Test - Validation Overlap For Unseen Targets :  0\n",
      "Train - Test - Validation Overlap For Unseen Drugs :  0\n",
      "Train - Test - Validation Overlap For Unseen Edges :  0\n",
      "Train Set :  (17138, 3)\n",
      "Nodes Test :  (5263, 3)\n",
      "Nodes Val :  (5263, 3)\n",
      "Edge Test :  (3906, 3)\n",
      "Edge Val :  (3906, 3)\n",
      "Positive / Negatative Ratio :  0.5792480648728345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vecnet_object.get_mol2vec_embeddings()\n",
    "vecnet_object.get_protvec_embeddings()\n",
    "\n",
    "vecnet_object.create_train_sets(unseen_nodes_flag = True,\n",
    "                                data_leak_check = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bade0752b84f4eae63211624718636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56da92ed4711459ea1a5a54f58a96fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Nodes AUC : 0.43\n",
      "Unseen Edges AUC : 0.4\n",
      "Unseen Nodes AUP : 0.47\n",
      "Unseen Edges AUP : 0.49\n",
      "\n",
      "Unseen Nodes AUC : 0.71\n",
      "Unseen Edges AUC : 0.7\n",
      "Unseen Nodes AUP : 0.69\n",
      "Unseen Edges AUP : 0.7\n",
      "\n",
      "Unseen Nodes AUC : 0.75\n",
      "Unseen Edges AUC : 0.73\n",
      "Unseen Nodes AUP : 0.72\n",
      "Unseen Edges AUP : 0.7\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df224fa7a39c468080d67701481c94a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Nodes AUC : 0.39\n",
      "Unseen Edges AUC : 0.42\n",
      "Unseen Nodes AUP : 0.45\n",
      "Unseen Edges AUP : 0.49\n",
      "\n",
      "Unseen Nodes AUC : 0.71\n",
      "Unseen Edges AUC : 0.69\n",
      "Unseen Nodes AUP : 0.72\n",
      "Unseen Edges AUP : 0.68\n",
      "\n",
      "Unseen Nodes AUC : 0.75\n",
      "Unseen Edges AUC : 0.71\n",
      "Unseen Nodes AUP : 0.71\n",
      "Unseen Edges AUP : 0.69\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797d95d9fdc04c1a85fa4b03a4af952c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Nodes AUC : 0.44\n",
      "Unseen Edges AUC : 0.41\n",
      "Unseen Nodes AUP : 0.46\n",
      "Unseen Edges AUP : 0.48\n",
      "\n",
      "Unseen Nodes AUC : 0.68\n",
      "Unseen Edges AUC : 0.71\n",
      "Unseen Nodes AUP : 0.67\n",
      "Unseen Edges AUP : 0.7\n",
      "\n",
      "Unseen Nodes AUC : 0.71\n",
      "Unseen Edges AUC : 0.74\n",
      "Unseen Nodes AUP : 0.65\n",
      "Unseen Edges AUP : 0.7\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654c40d13fb5416d825abfb4d1f27902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Nodes AUC : 0.44\n",
      "Unseen Edges AUC : 0.49\n",
      "Unseen Nodes AUP : 0.46\n",
      "Unseen Edges AUP : 0.53\n",
      "\n",
      "Unseen Nodes AUC : 0.72\n",
      "Unseen Edges AUC : 0.71\n",
      "Unseen Nodes AUP : 0.67\n",
      "Unseen Edges AUP : 0.71\n",
      "\n",
      "Unseen Nodes AUC : 0.74\n",
      "Unseen Edges AUC : 0.75\n",
      "Unseen Nodes AUP : 0.66\n",
      "Unseen Edges AUP : 0.73\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdd29801e554d96a7acf4cf507b9b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Nodes AUC : 0.42\n",
      "Unseen Edges AUC : 0.44\n",
      "Unseen Nodes AUP : 0.46\n",
      "Unseen Edges AUP : 0.52\n",
      "\n",
      "Unseen Nodes AUC : 0.67\n",
      "Unseen Edges AUC : 0.72\n",
      "Unseen Nodes AUP : 0.63\n",
      "Unseen Edges AUP : 0.72\n",
      "\n",
      "Unseen Nodes AUC : 0.69\n",
      "Unseen Edges AUC : 0.75\n",
      "Unseen Nodes AUP : 0.63\n",
      "Unseen Edges AUP : 0.72\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3bbaae8a59488ab1230aa22d855df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Nodes AUC : 0.39\n",
      "Unseen Edges AUC : 0.41\n",
      "Unseen Nodes AUP : 0.43\n",
      "Unseen Edges AUP : 0.47\n",
      "\n",
      "Unseen Nodes AUC : 0.69\n",
      "Unseen Edges AUC : 0.7\n",
      "Unseen Nodes AUP : 0.65\n",
      "Unseen Edges AUP : 0.69\n",
      "\n",
      "Unseen Nodes AUC : 0.72\n",
      "Unseen Edges AUC : 0.74\n",
      "Unseen Nodes AUP : 0.65\n",
      "Unseen Edges AUP : 0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vecnet_object.train_vecnet(model_name = 'vecnet_class_test',\n",
    "                           epochs = 3,\n",
    "                           version = 0,\n",
    "                           learning_rate = 0.00001,\n",
    "                           beta_1 = 0.9,\n",
    "                           beta_2 = 0.999,\n",
    "                           batch_size = 16,\n",
    "                           chunk_test_frequency = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vecnet_class_test_v0': {0: '_epoch_0_idx_0.model',\n",
       "  1: '_epoch_1_idx_0.model',\n",
       "  2: '_epoch_2_idx_0.model'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecnet_object.model_name_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch * Chunk) With Highest Unseen Node and Edge Score :  2\n",
      "(Epoch * Chunk) With Highest Unseen Node Score :  2\n",
      "(Epoch * Chunk) With Highest Unseen Edge Score :  2\n",
      "Validation Performance\n",
      "Best Model Suffix :  _epoch_2_idx_0.model\n",
      "Unseen Node AUC :  0.725797632817363 +/- 0.02329358871730686\n",
      "Unseen Node AUP :  0.6689468802904407 +/- 0.03167942244216613\n",
      "Unseen Edges AUC :  0.7353252305640452 +/- 0.0117381953913359\n",
      "Unseen Edges AUP :  0.7062604226306105 +/- 0.014499403534990064\n"
     ]
    }
   ],
   "source": [
    "vecnet_object.get_validation_results(model_name = 'vecnet_class_test_v0',\n",
    "                   show_plots = False,\n",
    "                   plot_title = 'Test Plots',\n",
    "                   num_cols = 2,\n",
    "                   plot_height = 1500,\n",
    "                   plot_width = 1500,\n",
    "                   write_plot_to_html = False,\n",
    "                   plot_dir = None,\n",
    "                   plot_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance : \n",
      "\n",
      "\tUnseen Nodes : \n",
      "\n",
      "\t\tAUC          :  0.7301269066303475 +/- 0.027035049410379233\n",
      "\t\tAUP          :  0.6712119089930869 +/- 0.03362075458573387\n",
      "\t\tMax F1 Score :  0.6907250884317606 +/- 0.016198227580438193\n",
      "\t\tF1 Threshold :  0.12666666666666668 +/- 0.014907119849998597\n",
      "\t\tConfusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred (0)</th>\n",
       "      <th>Pred (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True (0)</th>\n",
       "      <td>0.75 +/- 0.02</td>\n",
       "      <td>0.37 +/- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True (1)</th>\n",
       "      <td>0.25 +/- 0.02</td>\n",
       "      <td>0.63 +/- 0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred (0)       Pred (1)\n",
       "True (0)  0.75 +/- 0.02  0.37 +/- 0.03\n",
       "True (1)  0.25 +/- 0.02  0.63 +/- 0.03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tUnseen Edges : \n",
      "\n",
      "\t\tAUC          :  0.7382971684116503 +/- 0.00657318589583467\n",
      "\t\tAUP          :  0.7033040927572177 +/- 0.009990008088617981\n",
      "\t\tMax F1 Score :  0.7088187006501232 +/- 0.0044808720371446505\n",
      "\t\tF1 Threshold :  0.10833333333333334 +/- 0.02192157739660984\n",
      "\t\tConfusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred (0)</th>\n",
       "      <th>Pred (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True (0)</th>\n",
       "      <td>0.74 +/- 0.01</td>\n",
       "      <td>0.37 +/- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True (1)</th>\n",
       "      <td>0.26 +/- 0.01</td>\n",
       "      <td>0.63 +/- 0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred (0)       Pred (1)\n",
       "True (0)  0.74 +/- 0.01  0.37 +/- 0.02\n",
       "True (1)  0.26 +/- 0.01  0.63 +/- 0.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vecnet_object.get_test_results(model_name = None,\n",
    "                          optimal_validation_model = 2,\n",
    "                          drug_filter_list = [],\n",
    "                          target_filter_list = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
